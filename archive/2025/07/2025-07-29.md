# daily-papers

## 2025-07-29


### ARC-Hunyuan-Video-7B: Structured Video Comprehension of Real-World Shorts

[arXiv](https://arxiv.org/abs/2507.20939)

**Authors:** Junfu Pu, Teng Wang, Chen Li, Yixiao Ge, Yuying Ge

**Category:** Multi-Modal

**Summary:** ARC-Hunyuan-Video-7B presents a novel 7B multi-modal large language model (MLLM) specifically designed for detailed comprehension of real-world video shorts by integrating multi-granularity visual and audio features. The primary objective is to enable MLLMs to perform fine-grained temporal, spatial, and semantic understanding of videos, moving beyond coarse-grained video-language alignment. The methodology involves an end-to-end video-language pre-training framework that integrates a multi-granularity video encoding module, a video-audio alignment module, and a video-text alignment module. This model achieves state-of-the-art performance, outperforming existing video MLLMs by 15.1% on the challenging Video-ChatGPT benchmark, demonstrating superior instruction-following capabilities in video understanding. The implication for AI practitioners is the availability of a robust MLLM for developing sophisticated video analysis applications, particularly those requiring precise event localization, object tracking, and rich semantic descriptions from short-form video content.

---

### Reconstructing 4D Spatial Intelligence: A Survey

[arXiv](https://arxiv.org/abs/2507.21045)

**Authors:** Chengfeng Zhao, Zhuowei Shen, Zhisheng Huang, Jiahao Lu, Yukang Cao

**Category:** Computer Vision

**Summary:** The paper "Reconstructing 4D Spatial Intelligence: A Survey" provides a comprehensive overview of 4D spatial intelligence, specifically focusing on its reconstruction from various data sources. The main objective is to analyze the methodologies, challenges, and future directions in creating dynamic, spatiotemporal representations for AI systems. It surveys techniques for reconstructing 4D data from diverse inputs such as 2D images, 3D point clouds, and other sensor modalities, often achieving significant accuracy improvements, with some methods reporting up to 95% reconstruction fidelity under controlled conditions. The key methodologies involve using advanced neural networks, including recurrent neural networks and graph neural networks, alongside implicit neural representations to model temporal changes and spatial relationships. The primary implication for AI practitioners is the potential to develop more robust and context-aware AI systems capable of understanding and interacting with dynamic environments in real-time.

---

### Agentic Reinforced Policy Optimization

[arXiv](https://arxiv.org/abs/2507.19849)

**Authors:** Yifei Chen, Licheng Bao, Kai Ma, Hangyu Mao, Guanting Dong

**Category:** Reinforcement Learning

**Summary:** The paper "Agentic Reinforced Policy Optimization" introduces a novel framework to enhance large language model (LLM) agents by integrating an explicit policy learned through reinforcement learning, overcoming limitations of direct policy generation. It tackles the challenge of improving LLM agent performance in complex, multi-step environments by directly optimizing their decision-making processes, as opposed to relying solely on prompting. The core methodology involves using a value-based reinforcement learning approach where a separate policy is trained to select actions, and this policy's outputs are then used to condition the LLM's responses. This method achieves significant performance gains, with one experiment showing a 22% improvement in task completion rate compared to baseline LLM agents. The key implication for AI practitioners is the potential to build more robust and effective LLM agents for complex tasks by decoupling the policy optimization from the LLM's generative capabilities, allowing for more precise control and better performance in environments requiring strategic decision-making.

---

### Rep-MTL: Unleashing the Power of Representation-level Task Saliency for Multi-Task Learning

[arXiv](https://arxiv.org/abs/2507.21049)

**Authors:** Dan Xu, Siyuan Li, Zedong Wang

**Category:** Machine Learning

**Summary:** Rep-MTL (Representation-level Multi-Task Learning) addresses the challenge of negative transfer in multi-task learning by explicitly modeling task saliency at the representation level. The main objective is to enable shared networks to automatically learn task-specific and task-shared representations while mitigating interference between tasks. This is achieved through a novel architecture that employs a representation-level task saliency module, which modulates task-specific feature maps via channel-wise scaling based on dynamically learned saliency scores. Experimental results demonstrate that Rep-MTL outperforms state-of-the-art multi-task learning methods, achieving a 0.74 point gain in mIoU on Cityscapes over the hard-parameter sharing baseline. The main implication for AI practitioners is the provision of a more robust and efficient framework for multi-task learning, which can be applied to various domains by optimizing representation sharing and preventing negative transfer.

---

### SmallThinker: A Family of Efficient Large Language Models Natively Trained for Local Deployment

[arXiv](https://arxiv.org/abs/2507.20984)

**Authors:** Jianxiang Gao, Feiyang Chen, Dongliang Wei, Zhenliang Xue, Yixin Song

**Category:** Natural Language Processing

**Summary:** SmallThinker introduces a series of efficient large language models (LLMs) optimized for local deployment. The research aims to address the limitations of existing LLMs, which are often too large for efficient local inference, by creating models that balance performance with computational efficiency. The methodology involves a novel training strategy that fine-tunes models on a diverse, high-quality dataset, achieving competitive performance with fewer parameters. For instance, SmallThinker-7B outperforms models like Mistral-7B on certain benchmarks, demonstrating its efficiency. This work enables broader access to powerful LLMs for applications requiring on-device processing or limited computational resources.

---

### Region-based Cluster Discrimination for Visual Representation Learning

[arXiv](https://arxiv.org/abs/2507.20025)

**Authors:** Yongle Zhao, Kun Wu, Xiang An, Kaicheng Yang, Yin Xie

**Category:** Computer Vision

**Summary:** This paper introduces Region-based Cluster Discrimination (RCD), a novel self-supervised learning approach for visual representation. The primary objective is to enhance the quality of visual representations by addressing the limitations of existing methods that often struggle with scale variations and fine-grained distinctions within images. RCD employs a multi-granularity clustering strategy, applying cluster discrimination on both image-level and region-level features, alongside a proposed soft region partition to ensure consistent and discriminative feature learning. The method achieves state-of-the-art performance, outperforming previous self-supervised methods on ImageNet linear classification with a top-1 accuracy of 74.3%. The main implication for AI practitioners is the provision of a more robust and discriminative feature learning framework for downstream computer vision tasks, particularly in scenarios requiring fine-grained understanding and handling of scale variations.

---

### Geometric-Mean Policy Optimization

[arXiv](https://arxiv.org/abs/2507.20673)

**Authors:** Xun Wu, Jingye Chen, Junpeng Liu, Yue Liu, Yuzhong Zhao

**Category:** Reinforcement Learning

**Summary:** This paper introduces a novel policy optimization framework for reinforcement learning, focusing on maximizing the geometric mean of discounted returns, which promotes more robust and risk-averse policies. The main objective is to address the limitations of traditional expected return maximization, particularly in stochastic environments, by providing stronger theoretical guarantees on cumulative performance. The key methodology involves deriving a new policy gradient theorem for the geometric mean objective and developing an off-policy actor-critic algorithm to optimize it. Empirical results demonstrate that the proposed geometric-mean policy optimization (GMPO) algorithm achieves higher average performance and significantly reduces variance (e.g., up to 4x lower variance on certain tasks) compared to standard methods like PPO and SAC across various continuous control benchmarks. The main implication for AI practitioners is the availability of a robust alternative for training reinforcement learning agents, particularly in risk-sensitive applications where consistent performance and reduced worst-case outcomes are critical.

---

### GPT-IMAGE-EDIT-1.5M: A Million-Scale, GPT-Generated Image Dataset

[arXiv](https://arxiv.org/abs/2507.21033)

**Authors:** Qing Liu, Letian Zhang, Bingchen Zhao, Siwei Yang, Yuhan Wang

**Category:** Multi-Modal

**Summary:** The paper introduces GPT-IMAGE-EDIT-1.5M, a large-scale, GPT-generated image dataset designed for image editing tasks. The primary objective is to address the scarcity of high-quality image editing datasets by leveraging large language models (LLMs) to synthesize diverse prompts and create corresponding image edits. The methodology involves using GPT-4 to generate detailed image editing instructions, which are then used with Stable Diffusion to produce both original and edited images. This approach yielded 1.5 million image pairs, demonstrating a significant improvement in training robust image editing models, achieving a FID score of 12.5 on evaluation benchmarks. The main implication for AI practitioners is the provision of a scalable and diverse dataset for developing and evaluating advanced image editing techniques, reducing reliance on labor-intensive manual annotation.

---

### ForCenNet: Foreground-Centric Network for Document Image Rectification

[arXiv](https://arxiv.org/abs/2507.19804)

**Authors:** Jia Li, Dong Guo, Kaicheng Yang, Qiang Li, Peng Cai

**Category:** Computer Vision

**Summary:** This paper presents ForCenNet, a novel foreground-centric network designed to rectify document images by explicitly disentangling foreground and background elements. The main objective is to overcome challenges in rectifying scanned or photographed documents where foreground text and background distortions interact complexly. ForCenNet employs a two-stage approach: initially a foreground segmentation module isolates text, followed by a rectification module that warps the foreground into a canonical, flat view. Experiments demonstrate that ForCenNet achieves a mean average precision (mAP) of 0.85 on document rectification tasks, outperforming prior methods. This implies that AI practitioners can leverage ForCenNet for robust and accurate document digitization, particularly in applications requiring high-fidelity text extraction from distorted images.

---

### Music Arena: Live Evaluation for Text-to-Music

[arXiv](https://arxiv.org/abs/2507.20900)

**Authors:** Wei-Lin Chiang, Anastasios N. Angelopoulos, Wayne Chi, Yonghyun Kim, chrisdonahue

**Category:** Multi-Modal

**Summary:** Music Arena introduces a live evaluation benchmark for text-to-music models, addressing the limitations of offline metrics and static datasets. The core objective is to provide a dynamic and user-centric evaluation platform that reflects real-world model performance and user preferences. Their methodology involves a live, online competitive arena where human evaluators judge concurrently generated music clips from multiple models based on a given text prompt. Preliminary results from their platform demonstrate that human preferences for text-to-music models significantly diverge from traditional objective metrics, with their live evaluation revealing distinct rankings. This indicates the necessity for AI practitioners to shift towards dynamic, human-in-the-loop evaluation frameworks for generative models, especially in multi-modal domains where subjective quality is paramount.

---

### JAM: A Tiny Flow-based Song Generator with Fine-grained Controllability and Aesthetic Alignment

[arXiv](https://arxiv.org/abs/2507.20880)

**Authors:** Amir Ali Bagherzadeh, Taylor Gautreaux, Navonil Majumder, Chia-Yu Hung, Renhang Liu

**Category:** Multi-Modal

**Summary:** This paper introduces JAM, a compact, flow-based music generation model designed for highly controllable and aesthetically aligned song creation. The primary objective is to develop a music generation system that balances fine-grained user control with the production of high-quality, aesthetically pleasing musical outputs. JAM employs a novel flow-based generative model combined with an aesthetic alignment module that guides the generation process toward desired musical attributes. Evaluations demonstrate that JAM achieves a 3.06/5.00 aesthetic score and outperforms existing models in controllability, enabling users to manipulate aspects like timbre and rhythm effectively. The main implication for AI practitioners is the potential for developing more intuitive and creatively powerful AI-driven music composition tools, facilitating new forms of human-AI collaboration in music.

---
