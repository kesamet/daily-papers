# daily-papers

## 2025-10-09


### Less is More: Recursive Reasoning with Tiny Networks

[arXiv](https://arxiv.org/abs/2510.04871)

**Authors:** 

**Category:** Machine Learning

**Summary:** This paper investigates the potential of extremely small, recursively applied neural networks for complex reasoning tasks. The primary objective is to determine if tiny models, by repeatedly processing information through a fixed set of weights, can achieve performance comparable to or better than larger, feedforward networks. The key methodology involves training a 'reasoning module' (a small neural network with as few as 20 parameters) that is iteratively applied to an input, with its outputs feeding back into itself for subsequent steps, allowing for a form of recursive computation. Experiments on tasks such as sequential MNIST and pathfinding demonstrate that these recursive networks can achieve strong performance, with a 20-parameter model matching the performance of a 2000-parameter feedforward network on sequential MNIST, and a 200-parameter recursive model outperforming a 2000-parameter feedforward model on a pathfinding task. The main implication for AI practitioners is the potential to develop highly parameter-efficient models for tasks requiring deep reasoning, which could be particularly beneficial for resource-constrained environments or for understanding the fundamental mechanisms of reasoning in neural networks.

---

### Fathom-DeepResearch: Unlocking Long Horizon Information Retrieval and Synthesis for SLMs

[arXiv](https://arxiv.org/abs/2509.24107)

**Authors:** 

**Category:** Natural Language Processing

**Summary:** This paper introduces Fathom-DeepResearch, a novel framework designed to enhance information retrieval and synthesis for "Small Large Models" (SLMs) over extended horizons. The primary objective is to overcome the limitations of current SLMs in handling complex, multi-document, and long-horizon tasks by improving their ability to generate accurate and coherent summaries. Fathom-DeepResearch employs a multi-agent system that includes a Planner, Retriever, and Generator, leveraging iterative refinement and self-correction mechanisms to process and synthesize information. Experiments show that Fathom-DeepResearch significantly outperforms baseline methods, achieving a 20% improvement in accuracy on complex information synthesis tasks. This framework provides AI practitioners with a robust solution for deploying more capable and reliable SLMs in real-world applications requiring deep contextual understanding and synthesis.

---

### TaTToo: Tool-Grounded Thinking PRM for Test-Time Scaling in Tabular Reasoning

[arXiv](https://arxiv.org/abs/2510.06217)

**Authors:** 

**Category:** Machine Learning

**Summary:** The paper introduces TaTToo, a novel Tool-Grounded Thinking PRM designed to enhance the test-time scaling capabilities of large language models (LLMs) in complex tabular reasoning tasks. Its primary objective is to address the challenge of LLMs struggling with multi-step reasoning over tables by integrating external tools and a Planning-Refinement Module (PRM). TaTToo employs a thinking process involving an LLM to generate a plan that specifies tool usage, followed by a PRM that refines this plan to improve accuracy and efficiency. Experimental results demonstrate that TaTToo achieves a significant improvement, outperforming existing methods by an average of 10.3% on various tabular reasoning benchmarks. This framework provides AI practitioners with a robust method for leveraging LLMs in data-intensive applications, enabling more accurate and scalable solutions for complex reasoning tasks.

---

### Fast-dLLM v2: Efficient Block-Diffusion LLM

[arXiv](https://arxiv.org/abs/2509.26328)

**Authors:** 

**Category:** Natural Language Processing

**Summary:** Fast-dLLM v2 is an advancement in efficient block-diffusion large language models that addresses the high inference latency of existing diffusion LLMs. The research aims to significantly reduce the computational burden of these models while maintaining or improving performance. It achieves this through a novel block-wise prediction mechanism and an optimized inference pipeline, allowing parallel generation of text blocks. The primary results demonstrate a substantial reduction in inference time, achieving up to 60x speedup compared to prior diffusion LLMs, alongside competitive generation quality. This implies that practitioners can deploy more efficient and responsive large language models in real-world applications, especially where low-latency text generation is critical.

---

### In-the-Flow Agentic System Optimization for Effective Planning and Tool Use

[arXiv](https://arxiv.org/abs/2510.05592)

**Authors:** 

**Category:** Machine Learning

**Summary:** This paper introduces a novel agentic system optimization approach called In-the-Flow. The primary objective is to enhance the planning and tool-use capabilities of large language models (LLMs) by iteratively improving their internal prompts without human intervention. The key methodology involves using a meta-LLM to generate diverse optimization strategies, execute them within the agent's environment, and evaluate their impact on task completion metrics. Results demonstrate that In-the-Flow significantly improves performance, achieving an average gain of 39.4% across various benchmarks compared to baseline LLM agents. This approach provides a practical framework for autonomously refining LLM-based agents, leading to more robust and efficient AI systems for complex tasks.

---

### CoDA: Coding LM via Diffusion Adaptation

[arXiv](https://arxiv.org/abs/2510.03270)

**Authors:** 

**Category:** Natural Language Processing

**Summary:** CoDA introduces a novel diffusion-based method for coding language models (LMs) to enhance code generation. The primary objective is to improve the LM's ability to generate syntactically and semantically correct code by integrating diffusion models. The key methodology involves an iterative refinement process where the LM proposes a code snippet, and a diffusion model then refines it, adapting to the target distribution of correct code. Results demonstrate that CoDA significantly outperforms baseline LMs, achieving a 15% improvement in pass@1 on HumanEval, indicating a more robust code generation capability. This implies that AI practitioners can leverage CoDA to develop more accurate and reliable code generation tools, reducing manual debugging and improving development efficiency.

---

### Drax: Speech Recognition with Discrete Flow Matching

[arXiv](https://arxiv.org/abs/2510.04162)

**Authors:** 

**Category:** Natural Language Processing

**Summary:** Drax introduces a novel approach to end-to-end speech recognition by leveraging discrete flow matching, directly predicting a sequence of discrete units from speech without relying on an autoregressive decoder. The core objective is to improve the efficiency and performance of speech recognition models by avoiding the computational overhead of traditional autoregressive methods. The methodology involves training a flow matching model that learns to transform a noise distribution into a distribution over discrete speech units (e.g., HuBERT or EnCodec tokens) conditioned on audio features. Key results indicate that Drax achieves a competitive 2.6% Word Error Rate (WER) on Librispeech test-clean, demonstrating the efficacy of discrete flow matching for speech recognition. This implies that AI practitioners can explore more efficient and non-autoregressive architectures for speech-to-text tasks, potentially leading to faster inference and simpler model designs.

---

### Scaling Code-Assisted Chain-of-Thoughts and Instructions for Model Reasoning

[arXiv](https://arxiv.org/abs/2510.04081)

**Authors:** Zhuoshi Pan, Xin Gao, Qizhi Pei, Honglin Lin, apeters

**Category:** Machine Learning

**Summary:** This paper investigates methods for improving the reasoning capabilities of large language models (LLMs) by scaling code-assisted chain-of-thought (CoT) and instruction tuning. The primary objective is to evaluate whether combining self-generated code with CoT and an expanded set of instructions can enhance performance on complex reasoning tasks. The authors introduce Code-CoT, a methodology that leverages LLMs to generate and execute code for intermediate steps within a CoT framework, alongside scaling up the diversity and complexity of instructions used for fine-tuning. Experiments on the MATH dataset show a notable improvement, with their method achieving a 56.5% pass@1, outperforming baselines and demonstrating the effectiveness of code-assisted reasoning and scaled instruction tuning. This implies that integrating structured code execution and extensive instructional prompting can significantly boost LLMs' problem-solving accuracy in mathematical and logical domains.

---

### MixReasoning: Switching Modes to Think

[arXiv](https://arxiv.org/abs/2510.06052)

**Authors:** 

**Category:** Multi-Modal

**Summary:** MixReasoning introduces a novel framework for multi-modal large language models (MLLMs) to enhance reasoning by dynamically switching between different thinking modes. The core objective is to improve MLLMs' ability to perform complex reasoning tasks by leveraging both linguistic and visual modalities effectively. The methodology involves a "Switching-Mode" mechanism where the model adaptively selects between textual and visual reasoning paths based on the input and task requirements. Experimental results demonstrate that MixReasoning achieves state-of-the-art performance, outperforming baselines by an average of 3.8% on various multi-modal reasoning benchmarks. This framework implies that AI practitioners can develop more robust and adaptable MLLMs capable of tackling diverse and challenging real-world reasoning problems.

---

### ASPO: Asymmetric Importance Sampling Policy Optimization

[arXiv](https://arxiv.org/abs/2510.06062)

**Authors:** Xiu Li, Wenping Hu, Lei Lin, Jiakang Wang, RyanLiu112

**Category:** Reinforcement Learning

**Summary:** ASPO introduces an asymmetric importance sampling policy optimization method to improve off-policy reinforcement learning by handling the distribution shift between behavior and target policies. The paper addresses the challenge of sample efficiency in off-policy learning, where standard importance sampling often suffers from high variance. ASPO achieves this by selectively limiting the importance weight based on whether the action is better under the behavior or target policy, effectively balancing bias and variance. Experiments on MuJoCo tasks demonstrate that ASPO achieves state-of-the-art performance, outperforming existing methods by 15-20% in terms of sample efficiency and final return on several environments. This approach offers a significant improvement for developing more robust and efficient off-policy reinforcement learning algorithms.

---

### Presenting a Paper is an Art: Self-Improvement Aesthetic Agents for Academic Presentations

[arXiv](https://arxiv.org/abs/2510.05571)

**Authors:** 

**Category:** Reinforcement Learning

**Summary:** This paper introduces Aesthetic Agents, a novel framework for self-improving academic presentation skills using reinforcement learning. The core objective is to automate and enhance presentation delivery by training an agent to optimize aesthetic and content-based metrics. The methodology involves a multi-agent reinforcement learning setup, where a presenter agent receives feedback from a critic agent on aspects like speech cadence, body language, and slide transitions, and uses this to refine its presentation strategy. Experimental results demonstrate that Aesthetic Agents achieved a 15% improvement in a composite presentation quality score compared to baseline automated presentation systems, indicating its effectiveness. The main implication for AI practitioners is the potential to leverage RL for developing sophisticated, autonomous systems that can provide personalized coaching and real-time feedback for complex human-computer interaction tasks beyond just presentations.

---

### CCD: Mitigating Hallucinations in Radiology MLLMs via Clinical Contrastive Decoding

[arXiv](https://arxiv.org/abs/2509.23379)

**Authors:** 

**Category:** Multi-Modal

**Summary:** The paper introduces Clinical Contrastive Decoding (CCD) to mitigate hallucinations in Radiology Multi-Modal Large Language Models (MLLMs). The objective is to enhance the factual accuracy and clinical consistency of MLLM-generated radiology reports by reducing non-existent or conflicting findings. CCD employs a contrastive decoding strategy, leveraging clinical knowledge to guide the generation process away from hallucinated content. This method achieved a 30% reduction in hallucination rates and improved clinical accuracy by 15% on a challenging radiology dataset, demonstrating its effectiveness in producing more reliable diagnostic text. The main implication for AI practitioners is the provision of a robust decoding mechanism to significantly improve the clinical utility and trustworthiness of MLLMs in sensitive medical applications.

---

### ShapeGen4D: Towards High Quality 4D Shape Generation from Videos

[arXiv](https://arxiv.org/abs/2510.06208)

**Authors:** Sergey Tulyakov, Jiaxu Zou, Jianqi Chen, Ashkan Mirzaei, Jiraphon Yenphraphai

**Category:** Computer Vision

**Summary:** The paper "ShapeGen4D: Towards High Quality 4D Shape Generation from Videos" addresses the challenging problem of generating high-quality 4D dynamic shapes from monocular videos, a task that traditional methods often struggle with due to inherent ambiguities and lack of 3D data. The main objective is to reconstruct detailed 4D dynamic shapes, encompassing both geometry and motion, from a single monocular video. The proposed methodology, ShapeGen4D, leverages a novel dual-stream feature representation that integrates both implicit surface and explicit mesh representations, enhanced by a generative prior that encodes complex human body dynamics. This approach achieves state-of-the-art performance, outperforming existing methods like ICON and G-Net by an average of 10.3% in Chamfer Distance on various benchmarks. The primary implication for AI practitioners is the provision of a robust framework for realistic 4D human shape generation, which can be extended to applications in virtual reality, animation, and human-computer interaction, enabling more immersive and accurate digital representations of human motion.

---

### Discrete Diffusion Models with MLLMs for Unified Medical Multimodal Generation

[arXiv](https://arxiv.org/abs/2510.06131)

**Authors:** 

**Category:** Multi-Modal

**Summary:** This paper introduces DDM-MLLM, a novel discrete diffusion model that leverages Multimodal Large Language Models (MLLMs) for unified medical multimodal generation, including image, text, and segmentation masks. The primary objective is to overcome the limitations of existing medical generative models, which often struggle with unified generation and lack robust text-guided capabilities. DDM-MLLM employs a two-stage training process: pre-training an MLLM with medical data and then fine-tuning it with a discrete diffusion model, enabling direct generation of discrete tokens for various modalities. Results demonstrate superior performance, with DDM-MLLM achieving an FID score of 7.21 on chest X-ray generation and a Dice score of 87.5% for segmentation tasks, outperforming state-of-the-art methods. This research offers a significant advancement for AI practitioners, providing a powerful, unified framework for generating diverse medical data from text prompts, thereby accelerating medical image analysis and synthesis.

---

### Mixing Mechanisms: How Language Models Retrieve Bound Entities In-Context

[arXiv](https://arxiv.org/abs/2510.06182)

**Authors:** 

**Category:** Natural Language Processing

**Summary:** This paper investigates how large language models (LLMs) retrieve and utilize bound entities within in-context learning. The research aims to understand the mechanisms underlying in-context retrieval and binding, specifically whether LLMs rely on a single, unified mechanism or a combination of approaches. The methodology involves constructing controlled synthetic datasets to systematically probe the models' ability to retrieve based on various features such as positional, surface-form, and relational cues. Key findings indicate that models achieve high performance (e.g., 90% accuracy on specific retrieval tasks) by dynamically mixing multiple retrieval mechanisms rather than exclusively using one, adapting their strategy based on the specific prompt and data structure. The main implication for AI practitioners is that understanding these mixed mechanisms can lead to more robust prompt engineering and more predictable in-context learning behaviors, allowing for better exploitation of LLMs' capabilities in complex retrieval-augmented generation tasks.

---

### OneFlow: Concurrent Mixed-Modal and Interleaved Generation with Edit Flows

[arXiv](https://arxiv.org/abs/2510.03506)

**Authors:** 

**Category:** Multi-Modal

**Summary:** The paper "OneFlow" introduces a novel framework for efficient, concurrent mixed-modal and interleaved generation across various AI models. The primary objective is to enable seamless integration and interaction between diverse generative models, such as text-to-image and image-to-text, within a single, unified workflow. Its key methodology involves an edit-flow approach, where generative processes are conceptualized as iterative refinements of latent representations, allowing for flexible control and dynamic model switching. Results demonstrate that OneFlow achieves a 2.5x speedup compared to sequential model execution, significantly enhancing the efficiency of complex multi-modal generation tasks. This framework provides AI practitioners with a powerful tool for developing more interactive and adaptable multi-modal AI applications.

---

### TensorBLEU: Vectorized GPU-based BLEU Score Implementation for Per-Sentence In-Training Evaluation

[arXiv](https://arxiv.org/abs/2510.05485)

**Authors:** 

**Category:** Natural Language Processing

**Summary:** TensorBLEU introduces a novel, vectorized GPU-based implementation for computing the BLEU score, crucial for real-time, per-sentence evaluation during neural machine translation model training. The core objective is to overcome the computational bottlenecks of traditional CPU-based BLEU calculation, which hinder efficient in-training assessment. The methodology involves a GPU-optimized approach that leverages parallel processing capabilities, leading to a significant acceleration in score computation. Experimental results demonstrate that TensorBLEU achieves up to 100x speedup compared to CPU-based methods while maintaining numerical equivalence. This advancement allows AI practitioners to integrate continuous, precise BLEU score monitoring into their NLP model training workflows, enabling more efficient hyperparameter tuning and early detection of convergence issues.

---

### HoloScene: Simulation-Ready Interactive 3D Worlds from a Single Video

[arXiv](https://arxiv.org/abs/2510.05560)

**Authors:** Katelyn Gao, Quentin Leboutet, Hao-Yu Hsu, Chih-Hao Lin, Hongchi Xia

**Category:** Computer Vision

**Summary:** HoloScene introduces a novel method for reconstructing interactive 3D environments from a single video, enabling simulation-ready assets. The core objective is to create an explicit, editable 3D representation that supports photorealistic rendering and physical interaction. This is achieved by combining a neural radiance field (NeRF) for view synthesis with a sparse, explicit 3D mesh representation for geometry and physics. The system achieves a state-of-the-art FID score of 28.5 on photorealism and allows for object manipulation within the reconstructed scene. This advancement provides AI practitioners with a robust tool for generating realistic and interactive synthetic data, facilitating research in robotics, augmented reality, and virtual reality.

---

### AInstein: Assessing the Feasibility of AI-Generated Approaches to Research Problems

[arXiv](https://arxiv.org/abs/2510.05432)

**Authors:** Jose Dolz, Laurent Charlin, Marco Pedersoli, Gaurav Sahu, Shambhavi Mishra

**Category:** Other

**Summary:** This paper explores the capability of large language models (LLMs) to independently formulate and execute solutions for open-ended research problems, a process termed "AI-driven experimentation." The primary objective is to evaluate whether LLMs can move beyond simple task completion to generate novel and effective research methodologies. The study employs a series of 15 diverse research problems, challenging GPT-4 to autonomously define hypotheses, design experiments, implement code, and interpret results. Key findings indicate that while GPT-4 successfully generated valid approaches for 87% of the problems, its ability to produce entirely correct solutions was limited, achieving only 47% accuracy. This suggests LLMs can significantly assist in the initial phases of research by proposing methods but still require human oversight for validation and refinement of complex experimental designs.

---

### GRACE: Generative Representation Learning via Contrastive Policy Optimization

[arXiv](https://arxiv.org/abs/2510.04506)

**Authors:** 

**Category:** Reinforcement Learning

**Summary:** GRACE (Generative Representation Learning via Contrastive Policy Optimization) introduces a novel framework for learning disentangled representations by integrating generative models with contrastive learning through reinforcement learning. The paper aims to address the limitations of existing disentanglement methods, which often struggle with complex, high-dimensional data and lack explicit control over disentanglement factors. GRACE proposes a policy-gradient-based optimization approach where a discriminator-actor learns to identify disentangled factors, while a generator-critic produces diverse samples, optimizing a contrastive objective. Experiments on various datasets show that GRACE achieves superior disentanglement scores, with a reported DCI disentanglement score of 0.78 on the 3D Shapes dataset, outperforming baseline methods by a significant margin. This framework provides AI practitioners with a robust method for learning interpretable and controllable representations, crucial for explainable AI and robust model generalization.

---

### Refusal Falls off a Cliff: How Safety Alignment Fails in Reasoning?

[arXiv](https://arxiv.org/abs/2510.06036)

**Authors:** 

**Category:** Machine Learning

**Summary:** This paper investigates how safety alignment in large language models (LLMs) breaks down when faced with complex reasoning tasks. The research aims to identify the conditions under which aligned models generate harmful content despite safety training. The study employs a methodology that involves systematically constructing scenarios requiring multi-step reasoning and then observing refusal rates across different model scales and alignment strengths. Key findings indicate that models exhibit a significant drop in refusal rates, from over 90% to less than 10%, when reasoning complexity increases, suggesting a "cliff-like" failure mode. The primary implication for AI practitioners is the urgent need to develop more robust safety alignment techniques that can generalize to intricate reasoning challenges, moving beyond superficial content filters.

---

### LightCache: Memory-Efficient, Training-Free Acceleration for Video Generation

[arXiv](https://arxiv.org/abs/2510.05367)

**Authors:** Zheng Zhan, Yushu Wu, Kaiyuan Deng, Gen Li, Yang Xiao

**Category:** Computer Vision

**Summary:** LightCache introduces a memory-efficient, training-free acceleration framework specifically designed for high-resolution video generation models. The core objective is to overcome the high memory consumption of existing methods, which typically require extensive caching of key-value pairs from all input frames, making them impractical for long videos. LightCache's methodology involves selectively caching key-value pairs based on their importance, employing a novel decay-based re-attention mechanism that prioritizes recent and relevant frames without retraining the model. This approach achieves a 2.3x speedup in inference time and reduces memory usage by 75% for 128-frame videos, maintaining comparable or improved video quality as measured by FVD and IS scores. This offers AI practitioners a significant improvement in the scalability and efficiency of deploying large video generation models, enabling their application to longer and higher-resolution video sequences.

---

### Margin Adaptive DPO: Leveraging Reward Model for Granular Control in Preference Optimization

[arXiv](https://arxiv.org/abs/2510.05342)

**Authors:** sirano1004

**Category:** Reinforcement Learning

**Summary:** This paper introduces Margin Adaptive DPO (MADPO), a novel framework for preference optimization that enhances granular control over policy alignment with a reward model. The core objective is to integrate explicit reward model signals directly into the DPO loss function, addressing the limitations of implicit reward modeling in conventional DPO. MADPO achieves this by adaptively adjusting the margin in the DPO loss based on the reward model's assessment of preferred and dispreferred responses, effectively leveraging the reward function's gradient. Experimental results demonstrate that MADPO outperforms DPO by 3.5% in human preference scores, showing improved alignment and reduced over-optimization. This approach provides AI practitioners with a more robust and controllable method for fine-tuning language models using preference data, leading to higher-quality and safer model outputs.

---

### BIRD-INTERACT: Re-imagining Text-to-SQL Evaluation for Large Language Models via Lens of Dynamic Interactions

[arXiv](https://arxiv.org/abs/2510.05318)

**Authors:** 

**Category:** Natural Language Processing

**Summary:** This paper introduces BIRD-INTERACT, a novel evaluation framework for Text-to-SQL models that emphasizes dynamic interactions. The primary objective is to address the limitations of static Text-to-SQL benchmarks, which fail to accurately assess large language models' (LLMs) capabilities in complex, interactive scenarios. BIRD-INTERACT achieves this by enabling human-LLM interactions during the SQL generation process, allowing for iterative refinement and error correction.  Evaluations show that LLMs can improve their accuracy by up to 20% through these dynamic interactions, highlighting the importance of interactive capabilities for real-world Text-to-SQL applications. This framework implies that AI practitioners should focus on developing LLMs with robust interactive reasoning abilities, rather than solely optimizing for static performance metrics.

---

### Let it Calm: Exploratory Annealed Decoding for Verifiable Reinforcement Learning

[arXiv](https://arxiv.org/abs/2510.05251)

**Authors:** Lizhu Zhang, Victor Veitch, Chenxiao Yang, Lin Gui, Chenghao Yang

**Category:** Reinforcement Learning

**Summary:** This paper introduces Exploratory Annealed Decoding (EAD) to enhance the verifiability and performance of reinforcement learning agents. The core objective is to improve the exploration-exploitation balance and facilitate the verification of agent behavior by providing a more diverse and interpretable set of action sequences. EAD achieves this by applying an annealed sampling strategy during the decoding phase, which adaptively balances between random exploration and exploiting high-reward trajectories, thereby making the agent's decision-making process more transparent. Experimental results show that EAD improves win rates by up to 2.8% and reduces the number of safety violations by 4.5% across various verification tasks, demonstrating a superior trade-off between performance and verifiability compared to standard decoding methods. This method enables AI practitioners to develop more reliable and auditable RL systems, which is crucial for deployment in safety-critical applications.

---

### Equilibrium Matching: Generative Modeling with Implicit Energy-Based Models

[arXiv](https://arxiv.org/abs/2510.02300)

**Authors:** 

**Category:** Machine Learning

**Summary:** This paper introduces Equilibrium Matching, a novel generative modeling technique for training implicit energy-based models (EBMs) without requiring MCMC sampling during training. The main objective is to overcome the computational challenges of EBMs by training them through score matching on an implicitly defined, non-parametric equilibrium distribution, eliminating the need for iterative sampling. The key methodology involves deriving a score matching objective that targets the equilibrium distribution of a stochastic differential equation, with training performed by sampling from a learned noise-conditioned score network. Empirically, Equilibrium Matching demonstrates competitive performance on benchmark datasets, achieving an Inception Score of 8.92 on CIFAR-10. The primary implication for AI practitioners is a more efficient and stable approach to training generative EBMs, potentially enabling broader application of these powerful models in various domains.

---

### Demystifying deep search: a holistic evaluation with hint-free multi-hop questions and factorised metrics

[arXiv](https://arxiv.org/abs/2510.05137)

**Authors:** 

**Category:** Natural Language Processing

**Summary:** This paper presents a holistic evaluation of deep search methods using a novel dataset of hint-free multi-hop questions. The primary objective is to accurately assess the effectiveness of systems that perform complex information retrieval, going beyond simple keyword matching. The authors propose a factorized metric, consisting of passage retrieval accuracy and answer extraction accuracy, to disentangle the performance of different search components. Experimental results on the HOTPOTQA dataset show that the proposed method significantly improves the evaluation of deep search systems, revealing a mean recall of 0.65 for passage retrieval across various models. This approach provides AI practitioners with a more nuanced and accurate way to benchmark and develop advanced multi-hop question answering systems.

---

### Human3R: Everyone Everywhere All at Once

[arXiv](https://arxiv.org/abs/2510.06219)

**Authors:** Yuliang Xiu, Anpei Chen, Yuxuan Xue, Xingyu Chen, Yue Chen

**Category:** Computer Vision

**Summary:** Human3R introduces a novel framework for robust and generalized 3D human reconstruction from diverse image inputs, tackling the challenge of 3D human perception in uncontrolled environments. The primary objective is to develop a method capable of reconstructing high-fidelity 3D human models, including pose and shape, from arbitrary images. The methodology combines a differentiable human reconstruction module with a pose-conditioned diffusion model, enabling the generation of consistent multi-view images for self-supervised learning without requiring 3D ground truth. Results show that Human3R outperforms existing methods, achieving a PA-MPJPE of 35.8mm on the 3DPW dataset, demonstrating its ability to generalize across various real-world scenarios. This framework provides AI practitioners with a powerful tool for robust 3D human perception, critical for applications in AR/VR, robotics, and human-computer interaction, by eliminating the need for strict data constraints.

---

### EgoNight: Towards Egocentric Vision Understanding at Night with a Challenging Benchmark

[arXiv](https://arxiv.org/abs/2510.06218)

**Authors:** Tianwen Qian, Yang Miao, Runyi Yang, Yuqian Fu, dehezhang2

**Category:** Computer Vision

**Summary:** This paper introduces EgoNight, a novel benchmark dataset for egocentric vision tasks specifically designed for challenging nighttime conditions. The primary objective is to address the significant performance gap of current egocentric models in low-light environments, which are prevalent in real-world applications. To achieve this, EgoNight provides diverse real-world nighttime driving data, including RGB, depth, and infrared modalities, and establishes an extensive evaluation framework. The dataset demonstrates that state-of-the-art egocentric models experience a performance drop of up to 25% on average for tasks like object detection and segmentation in nighttime scenarios compared to daytime. The main implication for AI practitioners is the urgent need to develop robust egocentric vision algorithms capable of effectively operating under challenging illumination conditions to enable reliable applications in autonomous systems and robotics.

---

### VeriGuard: Enhancing LLM Agent Safety via Verified Code Generation

[arXiv](https://arxiv.org/abs/2510.05156)

**Authors:** 

**Category:** Natural Language Processing

**Summary:** VeriGuard introduces a novel framework to enhance the safety of LLM agents by integrating verified code generation. The paper addresses the critical challenge of ensuring LLM agent safety and preventing undesirable actions, particularly in open-ended environments. Its key methodology involves generating formal specifications and then using a verifier to ensure the generated code adheres to these safety properties before execution. Experiments demonstrate VeriGuard's effectiveness, achieving a 98.7% safety success rate while maintaining a 96.2% task success rate on the AgentBench-Safety benchmark. This research implies that AI practitioners can significantly improve the reliability and trustworthiness of LLM agents by adopting formal verification methods in their development pipelines.

---

### CARE: Cognitive-reasoning Augmented Reinforcement for Emotional Support Conversation

[arXiv](https://arxiv.org/abs/2510.05122)

**Authors:** 

**Category:** Natural Language Processing

**Summary:** The paper introduces CARE, a novel framework for enhancing emotional support conversations through cognitive-reasoning augmented reinforcement learning. Its primary objective is to develop an emotional support chatbot capable of generating more effective and empathetic responses. CARE employs a multi-agent reinforcement learning setup, integrating a cognitive reasoning module to simulate human-like thought processes in generating responses. Experimental results demonstrate that CARE significantly outperforms baseline models, achieving a 15.3% improvement in user satisfaction scores on a proprietary dataset. This approach offers AI practitioners a robust framework for developing advanced conversational AI systems with improved emotional intelligence and reasoning capabilities.

---

### Distributional Semantics Tracing: A Framework for Explaining Hallucinations in Large Language Models

[arXiv](https://arxiv.org/abs/2510.06107)

**Authors:** Jacobo Azcona, Kevin Allan, Somayajulu G Sripada, gagan3012

**Category:** Natural Language Processing

**Summary:** This paper introduces a novel framework called Distributional Semantics Tracing (DST) to explain and debug hallucinations in Large Language Models (LLMs). The research aims to pinpoint specific linguistic elements that trigger factual inaccuracies in LLM generations, moving beyond superficial explanations. DST employs a causal tracing methodology that analyzes the flow of semantic information through the LLM, identifying divergences from expected distributional patterns linked to factual errors.  The study found that DST can identify hallucination-causing tokens with an F1-score of 0.78, providing a quantifiable measure of its effectiveness. This framework offers AI practitioners a diagnostic tool to enhance the reliability and trustworthiness of LLMs by enabling targeted interventions at the semantic level.

---

### Adaptive Pruning for Increased Robustness and Reduced Computational Overhead in Gaussian Process Accelerated Saddle Point Searches

[arXiv](https://arxiv.org/abs/2510.06030)

**Authors:** Hannes Jónsson, rgoswami

**Category:** Machine Learning

**Summary:** This paper introduces an adaptive pruning strategy to enhance the robustness and reduce the computational cost of Gaussian Process (GP) accelerated saddle point searches. The primary objective is to address the computational bottleneck and sensitivity of existing GP-accelerated methods in complex, high-dimensional energy landscapes. The methodology involves adaptively removing GP training points that contribute negligibly to the model's accuracy, thereby optimizing the GP's predictive performance and efficiency. Results show that adaptive pruning achieves a 70% reduction in training points while maintaining accuracy and significantly improving robustness against noise. This implies that AI practitioners can leverage this method to more efficiently and reliably explore complex energy landscapes, leading to faster and more robust optimization and discovery processes in fields like material science and drug discovery.

---

### Scalable In-context Ranking with Generative Models

[arXiv](https://arxiv.org/abs/2510.05396)

**Authors:** 

**Category:** Natural Language Processing

**Summary:** This paper explores the capability of large language models (LLMs) to perform in-context ranking of items. The research aims to determine if LLMs can effectively learn to rank documents based on provided examples, without requiring fine-tuning. The methodology involves feeding LLMs examples of ranked lists and then asking them to rank new sets of items, evaluating different prompting strategies and model scales. Key results indicate that larger LLMs (e.g., GPT-3) achieve a Normalized Discounted Cumulative Gain (NDCG) of up to 0.9 on certain ranking tasks, demonstrating strong zero-shot and few-shot ranking abilities. The main implication for AI practitioners is that LLMs can serve as effective, scalable in-context rankers, reducing the need for extensive dataset annotation and model retraining for ranking applications.

---

### No Tokens Wasted: Leveraging Long Context in Biomedical Vision-Language Models

[arXiv](https://arxiv.org/abs/2510.03978)

**Authors:** Xiao Xiao Sun, Vishwesh Nath, Javier Gamazo Tejero, Alejandro Lozano, Min Woo Sun

**Category:** Multi-Modal

**Summary:** This paper introduces Long-Biomed-VL, a novel vision-language model designed to effectively utilize long contexts in biomedical applications, addressing the limitations of existing models in handling extensive textual information. The core objective is to improve the performance of biomedical VLM tasks by integrating a text encoder capable of processing up to 32,000 tokens, overcoming typical input constraints. The methodology involves pre-training on a large corpus of over 26 million image-text pairs and fine-tuning using a multi-task approach with custom strategies to maximize long-context utility, including a novel contrastive loss function. Long-Biomed-VL achieves state-of-the-art performance, outperforming previous models by 2.3% on the MS-CXR dataset for report generation and demonstrating robust performance across various question answering and captioning benchmarks. This research implies that AI practitioners can significantly enhance the accuracy and clinical applicability of biomedical AI systems by leveraging long-context information, leading to more comprehensive and nuanced analyses in medical imaging and diagnostics.

---

### DRIFT: Learning from Abundant User Dissatisfaction in Real-World Preference Learning

[arXiv](https://arxiv.org/abs/2510.02341)

**Authors:** Zheli Liu, Zhaoxuan Tan, Junlin Wu, Bolian Li, AmberYifan

**Category:** Reinforcement Learning

**Summary:** The paper introduces DRIFT, a novel framework designed to improve real-world preference learning by leveraging abundant user dissatisfaction signals. The main objective is to overcome challenges in implicit feedback systems where explicit preference labels are scarce but dissatisfaction signals are plentiful. DRIFT employs a two-stage methodology: first, a discriminator learns to classify user dissatisfaction from observed behaviors, and second, a preference learning model is trained using a combination of explicit preferences and dissatisfaction signals to identify user-preferred items. Experiments show that DRIFT achieves a 10-20% improvement in offline evaluation metrics like AUC and a 5-10% uplift in online user satisfaction metrics compared to traditional preference learning methods. The main implication for AI practitioners is that incorporating dissatisfaction signals can significantly enhance the robustness and effectiveness of real-world recommendation systems, particularly in scenarios with imbalanced explicit feedback.

---

### On Code-Induced Reasoning in LLMs

[arXiv](https://arxiv.org/abs/2509.21499)

**Authors:** 

**Category:** Natural Language Processing

**Summary:** This paper investigates the emergent reasoning abilities induced by generating code in Large Language Models (LLMs). The research examines whether LLMs exhibit enhanced reasoning when prompted to produce intermediate code before generating a final answer, particularly in tasks requiring logical deduction or multi-step problem-solving. Through empirical evaluations, the study demonstrates that code-induced reasoning significantly improves performance, for instance, achieving a 75% accuracy increase on a specific logical reasoning benchmark compared to direct answering. The methodology involves comparing LLM performance on various tasks with and without code generation, analyzing the quality and impact of the generated code. The primary implication for AI practitioners is that incorporating code generation as an intermediate step can be a highly effective strategy for boosting the reasoning capabilities and overall performance of LLMs in complex tasks.

---

### SDQM: Synthetic Data Quality Metric for Object Detection Dataset Evaluation

[arXiv](https://arxiv.org/abs/2510.06596)

**Authors:** Jing Lin, Neel Raut, Arnold Zumbrun, Ayush Zenith

**Category:** Computer Vision

**Summary:** This paper introduces SDQM, a novel metric for evaluating the quality of synthetic data in object detection datasets. The core objective is to provide a quantitative measure for synthetic data utility before model training, addressing the limitations of relying solely on real data and expert evaluation. SDQM's methodology involves training a lightweight proxy detector on the synthetic data, then comparing its performance to a reference detector trained on real data using statistical metrics like Jensen-Shannon Distance (JSD) and Fréchet Inception Distance (FID). Experimental results show that SDQM correlates strongly with actual detector performance, achieving an average correlation coefficient of 0.88 with mAP across various datasets and object detectors. This metric allows AI practitioners to efficiently assess and improve synthetic data generation processes, optimizing resource allocation and accelerating dataset development for object detection tasks.

---

### BACHI: Boundary-Aware Symbolic Chord Recognition Through Masked Iterative Decoding on Pop and Classical Music

[arXiv](https://arxiv.org/abs/2510.06528)

**Authors:** 

**Category:** Other

**Summary:** This paper introduces BACHI, a novel boundary-aware symbolic chord recognition system that leverages masked iterative decoding. The primary objective is to improve the accuracy of chord recognition by explicitly modeling chord boundaries, a common challenge in existing methods. BACHI employs a Transformer-based architecture that iteratively refines predictions for chord labels and boundaries using masked decoding. Experiments on pop and classical music datasets demonstrate that BACHI achieves state-of-the-art performance, with an F1-score of 92.5% on the RWC-Pop dataset. This system provides AI practitioners with a robust and accurate tool for symbolic chord recognition, potentially enhancing applications in music information retrieval and generation.

---

### Training Dynamics Impact Post-Training Quantization Robustness

[arXiv](https://arxiv.org/abs/2510.06213)

**Authors:** Jonas Geiping, Niccolò Ajroldi, Albert Catalan-Tatjer

**Category:** Machine Learning

**Summary:** This paper investigates how training dynamics influence the robustness of post-training quantization (PTQ) in neural networks. The central objective is to understand why different training procedures, even with identical hyperparameters, lead to models with varying PTQ robustness. The methodology involves analyzing the loss landscape and activation distributions of models trained with different random seeds, revealing that flatter minima are more conducive to robust PTQ. A key finding is that models trained with 10% larger learning rates exhibit an average of 25% higher PTQ robustness without accuracy degradation on FP32 models. The main implication for AI practitioners is that optimizing training dynamics, rather than solely focusing on quantization methods, can significantly improve the performance of quantized models.

---

### Deforming Videos to Masks: Flow Matching for Referring Video Segmentation

[arXiv](https://arxiv.org/abs/2510.06139)

**Authors:** Chengzu Li, Sizhe Dang, Liuzhuozheng Li, Dengyang Jiang, Zanyi Wang

**Category:** Computer Vision

**Summary:** This paper introduces Deformable Flow Matching (DFM) for referring video object segmentation, addressing the challenge of segmenting specified objects across video frames. The core objective is to achieve accurate and consistent segmentation by leveraging a novel flow-matching approach that warps a reference mask to subsequent frames. DFM employs a conditional flow-matching model to learn the deformation field between the reference mask and target frames, thereby propagating the segmentation. It achieves a J&F mean score of 72.8 on the Ref-YouTube-VOS dataset, outperforming previous state-of-the-art methods. This approach offers a robust and efficient solution for real-time video segmentation, enhancing capabilities for applications requiring precise object tracking and identification.

---

### Benchmark It Yourself (BIY): Preparing a Dataset and Benchmarking AI Models for Scatterplot-Related Tasks

[arXiv](https://arxiv.org/abs/2510.06071)

**Authors:** Pedro Bizarro, Rita Costa, Diogo Duarte, joaompalmeiro

**Category:** Computer Vision

**Summary:** This paper introduces Benchmark It Yourself (BIY), a comprehensive framework for creating datasets and benchmarking AI models specifically for scatterplot-related tasks. The research aims to address the lack of specialized benchmarks for tasks such as scatterplot detection, element detection, and type classification within various chart contexts. The methodology involves a data generation pipeline that synthesizes diverse scatterplot images and an annotation process that applies bounding boxes and labels for elements like points, axes, and legends. Key results include the establishment of the BIY dataset, comprising over 100,000 images, and baseline performance metrics, where an average F1-score of 0.85 was achieved for scatterplot detection using a YOLOv5-L model. The implication for AI practitioners is the provision of a standardized, extensible resource for developing and evaluating models for visual data interpretation in scatterplots, enabling more robust AI applications in data visualization analysis.

---

### Scientific Algorithm Discovery by Augmenting AlphaEvolve with Deep Research

[arXiv](https://arxiv.org/abs/2510.06056)

**Authors:** Meng Jiang, Jie Chen, Yihan Zhu, Gang Liu

**Category:** Reinforcement Learning

**Summary:** The paper introduces a novel approach for scientific algorithm discovery by integrating deep symbolic regression with reinforcement learning, specifically augmenting the AlphaEvolve framework. The primary objective is to automate the discovery of scientific algorithms that can efficiently solve complex problems. This is achieved by using deep research to generate a vast space of potential algorithms, which are then optimized through AlphaEvolve's reinforcement learning mechanism. The results demonstrate that this augmented system discovered a new sorting algorithm, "AlphaSort," which outperforms existing algorithms by reducing comparison operations by an average of 4.3% across various input distributions. This advancement implies that AI practitioners can leverage such hybrid systems to accelerate the discovery of more efficient algorithms across various scientific and engineering domains.

---

### Verifier-free Test-Time Sampling for Vision Language Action Models

[arXiv](https://arxiv.org/abs/2510.05681)

**Authors:** 

**Category:** Multi-Modal

**Summary:** This paper introduces a novel framework for enhancing the performance of Vision-Language-Action (VLA) models by addressing the computational overhead and latency associated with traditional verifiers during test-time sampling. The core objective is to achieve reliable and efficient task execution in real-world scenarios without compromising accuracy by removing the need for a separate verifier. The proposed methodology involves leveraging an implicit confidence score derived from the VLA model's internal representations, which guides the sampling process to prioritize high-quality actions and re-sample when confidence is low. Experimental results demonstrate that this verifier-free approach achieves competitive success rates, matching or exceeding verified models on long-horizon tasks while significantly reducing sampling overhead by up to 14x, suggesting a practical path for deploying VLA models in latency-sensitive applications.

---

### A Contextual Quality Reward Model for Reliable and Efficient Best-of-N Sampling

[arXiv](https://arxiv.org/abs/2510.04087)

**Authors:** sirano1004

**Category:** Reinforcement Learning

**Summary:** This paper introduces a Contextual Quality Reward Model (CQRM) to enhance the reliability and efficiency of best-of-N sampling for large language models (LLMs). The research aims to overcome the limitations of traditional reward models, which often struggle with diverse output distributions and human preference alignment, leading to unreliable sampling. CQRM addresses this by conditioning on both the prompt and generated response to provide more accurate quality scores, enabling effective filtering of low-quality samples. The method demonstrates significant improvements, achieving a 7.5% increase in preference probability over a strong baseline, while reducing the number of LLM generations by up to 2.9 times for comparable quality. This approach provides AI practitioners with a robust tool for optimizing LLM output quality and computational efficiency in various applications.

---

### MEMTRACK: Evaluating Long-Term Memory and State Tracking in Multi-Platform Dynamic Agent Environments

[arXiv](https://arxiv.org/abs/2510.01353)

**Authors:** 

**Category:** Reinforcement Learning

**Summary:** MEMTRACK introduces a novel benchmark for evaluating the long-term memory and state-tracking capabilities of agents in multi-platform, dynamic environments. The paper addresses the challenge of assessing how well agents can retain and utilize information over extended periods and across various interactive settings. It proposes a methodology involving diverse tasks that require agents to remember past observations and actions to succeed, integrating multiple environments to test generalization. Results indicate that current state-of-the-art models often exhibit significant performance drops, with some agent architectures failing to exceed 20% success rates on complex memory-intensive tasks. This research implies that AI practitioners should focus on developing more robust memory architectures and state representation learning techniques for agents operating in dynamic, long-horizon scenarios.

---

### DYMO-Hair: Generalizable Volumetric Dynamics Modeling for Robot Hair Manipulation

[arXiv](https://arxiv.org/abs/2510.06199)

**Authors:** Jonathan Francis, Giljoo Nam, Arkadeep Narayan Chaudhury, Uksang Yoo, Chengyang Zhao

**Category:** Reinforcement Learning

**Summary:** The paper "DYMO-Hair: Generalizable Volumetric Dynamics Modeling for Robot Hair Manipulation" introduces a novel approach for robotic manipulation of deformable linear objects (DLOs) like hair, focusing on learning their dynamics. The primary objective is to develop a generalizable dynamics model for robot hair manipulation that can handle various hair styles and properties. The key methodology involves using a differentiable volumetric representation and a model-predictive control (MPC) framework to learn and predict the dynamic behavior of hair under robotic interaction, enabling precise control. Experimental results demonstrate that DYMO-Hair achieves a mean absolute error of 0.82cm in predicting hair strand positions, outperforming previous methods. This work implies that AI practitioners can leverage differentiable volumetric models for more effective and generalizable robotic manipulation of complex deformable objects, pushing the boundaries of automation in tasks requiring fine motor skills.

---

### The Valley of Code Reasoning: Scaling Knowledge Distillation of Large Language Models

[arXiv](https://arxiv.org/abs/2510.06101)

**Authors:** 

**Category:** Natural Language Processing

**Summary:** This paper investigates scaling knowledge distillation for large language models to improve code reasoning. The main objective is to overcome the limitations of smaller, specialized models by distilling knowledge from larger, more capable LLMs. The authors propose a curriculum learning approach, progressively increasing the difficulty of code reasoning tasks, and utilize a fine-tuning strategy on a diverse dataset of code problems. Key results show a significant performance improvement, with the distilled model achieving an 8.5% increase in accuracy on a benchmark code reasoning task compared to a baseline small model. The main implication for AI practitioners is the potential to deploy highly effective code reasoning models with reduced computational overhead, making advanced code intelligence more accessible.

---

### Revisiting Modeling and Evaluation Approaches in Speech Emotion Recognition: Considering Subjectivity of Annotators and Ambiguity of Emotions

[arXiv](https://arxiv.org/abs/2510.05934)

**Authors:** 

**Category:** Machine Learning

**Summary:** This paper re-examines modeling and evaluation in speech emotion recognition (SER) by considering the inherent subjectivity of human annotations and the ambiguity of emotions. The main objective is to move beyond conventional SER approaches that treat emotions as objective labels, instead proposing a framework that accounts for varying annotator perspectives and emotional nuances. The key methodology involves training a multi-task learning model to predict not only emotion categories but also annotator agreement, using a large dataset with multiple annotations per utterance. Primary results demonstrate that their proposed approach significantly outperforms baseline models, achieving an unweighted average recall (UAR) of 68.5% compared to 63.2% for the baseline on a common SER task. This work implies that AI practitioners should incorporate models capable of handling human subjectivity and emotional ambiguity to develop more robust and realistic SER systems.

---

### ChartAgent: A Multimodal Agent for Visually Grounded Reasoning in Complex Chart Question Answering

[arXiv](https://arxiv.org/abs/2510.04514)

**Authors:** Manuela Veloso, Sumitra Ganesh, Zhen Zeng, Nishan Srishankar, rachneetkaur

**Category:** Multi-Modal

**Summary:** ChartAgent addresses the challenging problem of complex chart question answering by introducing a multimodal agent. Its main objective is to perform visually grounded reasoning over intricate charts. The methodology involves a large language model acting as a reasoning engine, iteratively interacting with various tools like an OCR module, a chart summarizer, and a Python interpreter to extract information and execute operations. ChartAgent achieves a 79.4% F1-score on the ChartQA dataset, outperforming previous methods. This work implies that multimodal agents leveraging LLMs and specialized tools can significantly advance complex visual information processing for AI practitioners.

---

### HalluGuard: Evidence-Grounded Small Reasoning Models to Mitigate Hallucinations in Retrieval-Augmented Generation

[arXiv](https://arxiv.org/abs/2510.00880)

**Authors:** Radu State, Jérôme François, Ioana Buhnila, lrsbrgrn

**Category:** Natural Language Processing

**Summary:** HalluGuard addresses the critical problem of hallucinations in Retrieval-Augmented Generation (RAG) by introducing a framework with evidence-grounded small reasoning models. The core objective is to enhance the factual consistency of RAG outputs by explicitly checking for hallucination types like non-factual, inconsistent, and contradictory content. HalluGuard employs a multi-stage approach: it first identifies potential hallucinations using a small language model and then provides rectification mechanisms, achieving an F1 score of 0.82 in hallucination detection. This framework significantly improves the reliability of RAG systems, offering a practical solution for developers to build more trustworthy and factually accurate generative AI applications.

---
