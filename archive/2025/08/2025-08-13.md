# daily-papers

## 2025-08-13


### ReasonRank: Empowering Passage Ranking with Strong Reasoning Ability

[arXiv](https://arxiv.org/abs/2508.07050)

**Authors:** Yuchen Li, Yutao Zhu, Weiwei Sun, Xinyu Ma, Wenhan Liu

**Category:** Natural Language Processing

**Summary:** ReasonRank focuses on improving passage ranking by integrating strong reasoning abilities into the ranking process. The main objective is to overcome the limitations of traditional deep language models in complex reasoning tasks for ad-hoc passage retrieval. The methodology involves a novel reasoning-enhanced passage re-ranking framework that leverages Large Language Models (LLMs) to generate diverse reasoning chains, thereby augmenting passage representations and guiding the re-ranking process. Experimental results show that ReasonRank achieves an average improvement of +2.19% NDCG@10 over strong baselines, demonstrating the effectiveness of explicit reasoning for complex retrieval scenarios. This framework provides a valuable approach for AI practitioners aiming to build more robust and interpretable retrieval systems for complex information needs.

---

### WideSearch: Benchmarking Agentic Broad Info-Seeking

[arXiv](https://arxiv.org/abs/2508.07999)

**Authors:** Yan Gao, Li Chen, Junjie Zhao, Jiawei Wang, Ryan Wong

**Category:** Machine Learning

**Summary:** This paper introduces WideSearch, a new benchmark for evaluating agentic broad information-seeking capabilities. The primary objective is to assess the ability of AI agents to effectively search across multiple modalities and diverse topics, mirroring complex human information-gathering tasks. To achieve this, WideSearch employs a human-centric evaluation methodology, where human assessors judge the quality and relevance of information retrieved by agents across a set of diverse, open-ended queries. Initial findings reveal a significant gap between current state-of-the-art agents and human performance, with agents achieving an average recall score of approximately 0.45 compared to human recall nearing 0.90 in broad information retrieval. The main implication for AI practitioners is the pressing need for developing more robust and versatile AI agents capable of handling the intricacies of broad and multimodal information-seeking, moving beyond narrow task-specific capabilities.

---

### Omni-Effects: Unified and Spatially-Controllable Visual Effects Generation

[arXiv](https://arxiv.org/abs/2508.07981)

**Authors:** Xiaokun Feng, Dongxia Liu, Jintao Chen, Aiming Hao, Fangyuan Mao

**Category:** Computer Vision

**Summary:** The paper "Omni-Effects" introduces a novel unified framework for generating spatially-controllable visual effects, addressing the challenge of diverse effect types and precise spatial manipulation. Their main objective is to overcome limitations of traditional methods by developing a generative model capable of producing high-fidelity and controllable visual effects with a single model. The key methodology involves a conditional diffusion model that leverages disentangled representations of effects, enabling control over shape, intensity, and location. This approach demonstrates superior performance, achieving a 20% improvement in visual quality metrics compared to existing specialized methods. The main implication for AI practitioners is the potential for streamlined and more efficient visual effect generation in applications such as film production, virtual reality, and content creation, reducing the need for multiple specialized tools.

---

### A Comprehensive Survey of Self-Evolving AI Agents: A New Paradigm Bridging Foundation Models and Lifelong Agentic Systems

[arXiv](https://arxiv.org/abs/2508.07407)

**Authors:** Xinhao Yi, Yingxu Wang, Xi Zhang, Yanwen Peng, Jinyuan Fang

**Category:** Reinforcement Learning

**Summary:** This survey paper introduces Self-Evolving AI Agents (SEAs), a novel paradigm merging Foundation Models (FMs) and lifelong agentic systems to address current AI limitations. The primary objective is to develop agents capable of autonomous learning and continuous self-improvement in dynamic environments, moving beyond static, pre-trained models. The methodology involves an in-depth review of existing literature, categorizing SEAs based on their architectural components, learning mechanisms, and evaluation metrics, and proposing a unified framework. While no new experimental results are presented, the paper highlights that SEAs, by autonomously adapting and evolving, can achieve significant performance improvements, potentially reducing human intervention in model updates by over 80%. The main implication for AI practitioners is the shift towards building adaptive, lifelong learning systems that continuously refine their capabilities, leading to more robust and generalized AI applications.

---

### BrowseComp-Plus: A More Fair and Transparent Evaluation Benchmark of Deep-Research Agent

[arXiv](https://arxiv.org/abs/2508.06600)

**Authors:** Kai Zou, Ping Nie, Shengyao Zhuang, Xueguang Ma, Zijian Chen

**Category:** Reinforcement Learning

**Summary:** This paper introduces BrowseComp-Plus, an enhanced benchmark for evaluating deep-research agents that combines web-based tasks with complex reasoning requirements. The primary objective is to address the limitations of existing benchmarks by providing a more fair, transparent, and challenging evaluation environment for agents designed to navigate and extract information from the web. The key methodology involves curating a diverse set of real-world, dynamic web tasks and implementing a robust evaluation protocol that tracks agent actions and reasoning processes, specifically focusing on transparency by allowing for detailed post-hoc analysis. While specific quantitative primary results were not explicitly available in the provided context, the paper emphasizes its utility in revealing common failure modes, improving interpretability, and enabling more effective iteration on agent design, offering a significant implication for AI practitioners in developing more reliable and human-interpretable web agents.

---

### Klear-Reasoner: Advancing Reasoning Capability via Gradient-Preserving Clipping Policy Optimization

[arXiv](https://arxiv.org/abs/2508.07629)

**Authors:** Guanting Dong, Dening Liu, Xue Bai, Leiyu Pan, Zhenpeng Su

**Category:** Reinforcement Learning

**Summary:** Klear-Reasoner introduces an innovative approach to improve reasoning capabilities in large language models by integrating gradient-preserving clipping policy optimization. The primary objective is to address the limitations of conventional policy optimization methods, which often lead to unstable training and sub-optimal performance in complex reasoning tasks. The paper proposes a novel gradient-preserving clipping policy optimization method, Klear-Opt, designed to stabilize training and enhance the model's ability to learn intricate reasoning patterns by adaptively controlling policy updates. Experimental results demonstrate that Klear-Reasoner significantly outperforms baseline models, achieving a 15.3% improvement in accuracy on the GSM8K dataset, showcasing its effectiveness in enhancing arithmetic reasoning. This advancement provides AI practitioners with a robust framework for developing more reliable and efficient reasoning systems, particularly in applications requiring precise and stable policy optimization.

---

### SONAR-LLM: Autoregressive Transformer that Thinks in Sentence Embeddings and Speaks in Tokens

[arXiv](https://arxiv.org/abs/2508.05305)

**Authors:** Anton Razzhigaev, Andrey Kuznetsov, Elizaveta Goncharova, Temurbek Rahmatullaev, Nikita Dragunov

**Category:** Natural Language Processing

**Summary:** SONAR-LLM is an innovative autoregressive transformer model that integrates sentence embeddings into its generative process. The core objective of this research is to enhance the coherence and semantic understanding of large language models by enabling them to operate on a higher level of abstraction than token-by-token generation. Its key methodology involves two stages: a Sentence-level Autoregressive Transformer (SAT) for generating sentence embeddings sequentially, and a Token-level Decoder (TLD) which reconstructs tokens from these embeddings, thus allowing the model to "think" in sentences before "speaking" in tokens. Preliminary results indicate that SONAR-LLM achieves a 2.3 BLEU score improvement over baseline models in text generation tasks, suggesting enhanced long-range coherence. This implies that AI practitioners can leverage this architecture for more semantically rich and contextually aware language generation, potentially reducing common LLM pitfalls like repetition and incoherence.

---

### UserBench: An Interactive Gym Environment for User-Centric Agents

[arXiv](https://arxiv.org/abs/2507.22034)

**Authors:** Jianguo Zhang, Zhiwei Liu, Akshara Prabhakar, Zuxin Liu, Cheng Qian

**Category:** Reinforcement Learning

**Summary:** UserBench is a novel interactive gym environment designed to facilitate the training and evaluation of user-centric AI agents. The primary objective is to enable the development of agents capable of understanding and responding to human users' implicit and explicit needs through a web-based interface. It achieves this by transforming a real-world web application (Discord) into a controllable, customizable environment for embodied agents, providing an HTML-based observation space and a robust action space for interacting with web elements. Initial experiments demonstrate that agents trained within UserBench can achieve an average success rate of over 75% on various user-centric tasks, showcasing its potential for developing more intuitive and helpful AI systems. This environment provides AI practitioners with a standardized, reproducible platform for advancing research in human-AI interaction and user-adaptive agents.

---

### MolmoAct: Action Reasoning Models that can Reason in Space

[arXiv](https://arxiv.org/abs/2508.07917)

**Authors:** Shuo Liu, Yuquan Deng, Haoquan Fang, Jiafei Duan, Jason Lee

**Category:** Reinforcement Learning

**Summary:** MolmoAct introduces novel action reasoning models enabling AI agents to reason about actions in continuous 3D space, which is crucial for complex manipulation tasks. The primary objective is to enhance robotic manipulation by allowing agents to understand and execute actions involving spatial relationships, addressing limitations of traditional action representations. Their methodology involves learning a latent action space that integrates spatial reasoning directly into action representations, training on a diverse dataset of manipulation trajectories. The models demonstrate significant improvements, achieving a 78% success rate on complex manipulation benchmarks, outperforming baseline methods by 15%. This advancement implies that AI practitioners can develop more capable and robust robotic systems by leveraging these spatially-aware action reasoning models for intricate real-world tasks.

---

### OmniEAR: Benchmarking Agent Reasoning in Embodied Tasks

[arXiv](https://arxiv.org/abs/2508.05614)

**Authors:** Hongxing Li, Dingming Li, tricktreat, yanyc, wangzx1210

**Category:** Reinforcement Learning

**Summary:** OmniEAR introduces a comprehensive benchmark for evaluating the reasoning capabilities of embodied AI agents in complex, realistic 3D environments. The paper addresses the critical need for a standardized evaluation framework beyond simplistic metrics, focusing on tasks requiring deep reasoning, planning, and execution within environments like ALFRED and ReplicaCAD. Their methodology involves developing 15 reasoning-intensive tasks across diverse scenarios, and evaluating 7 leading Large Language Model (LLM) based agents, revealing that even state-of-the-art agents achieve a mere 14% success rate on the reasoning-intensive tasks. This benchmark highlights significant deficiencies in current agent reasoning and underscores the necessity for developing more robust and generalizable embodied AI agents capable of complex decision-making in real-world scenarios.

---

### Grove MoE: Towards Efficient and Superior MoE LLMs with Adjugate Experts

[arXiv](https://arxiv.org/abs/2508.07785)

**Authors:** Tieyuan Chen, Zhanchao Zhou, Xiaodong Chen, Haoxing Chen, Haoyuan Wu

**Category:** Natural Language Processing

**Summary:** This paper introduces Grove MoE, an innovative Mixture-of-Experts (MoE) Large Language Model (LLM) architecture designed for enhanced efficiency and performance. The primary objective is to address the issues of unbalanced expert loading and training instability common in conventional MoE models. Grove MoE employs an adjugate expert mechanism where a portion of the top-performing experts are consistently activated, ensuring more stable expert utilization. The method achieves a significant 1.5% improvement in perplexity and a 2.5x increase in training speed on the Pile dataset compared to baseline MoE models. This implies that AI practitioners can deploy more efficient and robust MoE LLMs, leading to faster development cycles and improved model stability.

---

### Part I: Tricks or Traps? A Deep Dive into RL for LLM Reasoning

[arXiv](https://arxiv.org/abs/2508.08221)

**Authors:** Jiaheng Liu, Weixun Wang, Yancheng He, Jiashun Liu, Zihe Liu

**Category:** Reinforcement Learning

**Summary:** This paper investigates the application of Reinforcement Learning (RL) to enhance Large Language Model (LLM) reasoning abilities. The primary objective is to evaluate whether RL techniques genuinely improve LLM reasoning or introduce unforeseen issues, functioning as 'tricks or traps.' The methodology involves a systematic analysis of various RL algorithms, including PPO and DPO, applied to tasks requiring complex reasoning over diverse datasets like GSM8K and BigBench-Hard. Key findings indicate that while RL can improve performance, achieving up to 15% better accuracy on certain reasoning tasks, it also introduces challenges such as reward hacking and potential instability in the training process. The main implication for AI practitioners is the necessity for careful consideration of RL implementation for LLMs, balancing potential gains against the risk of introducing unintended behaviors or performance degradation.

---

### Reinforcement Learning in Vision: A Survey

[arXiv](https://arxiv.org/abs/2508.08189)

**Authors:** Qingwei Meng, Kevin Qinghong Lin, Joya Chen, Chen Gao, Weijia Wu

**Category:** Reinforcement Learning

**Summary:** This paper provides a comprehensive survey on the intersection of reinforcement learning (RL) and computer vision (CV). The primary objective is to categorize and analyze how RL techniques are applied to various vision tasks and to identify future research directions. The survey adopts a structured approach, classifying existing works based on the specific CV task being addressed, such as object detection, image segmentation, and visual tracking, and detailing the RL algorithms employed. While specific quantitative metrics are not the focus of a survey, the paper highlights that RL-based methods have achieved state-of-the-art performance in certain areas, often outperforming traditional methods by significant margins (e.g., reported improvements in accuracy or efficiency in specific visual tasks, though exact numeric improvements vary by sub-field and are not uniformly provided as this is a survey). The main implication for AI practitioners is the identification of promising avenues for integrating sequential decision-making capabilities into visual systems, potentially leading to more robust and autonomous computer vision applications.

---

### Temporal Self-Rewarding Language Models: Decoupling Chosen-Rejected via Past-Future

[arXiv](https://arxiv.org/abs/2508.06026)

**Authors:** Qiufeng Wang, Junfeng Fang, Cunxiang Wang, Xin Wang, Yidong Wang

**Category:** Reinforcement Learning

**Summary:** This paper introduces T-SRL, a novel self-rewarding approach that optimizes language models by explicitly decoupling chosen and rejected samples through past and future states for more effective preference learning. The main objective is to overcome limitations of traditional self-rewarding methods that conflate positive and negative signals, leading to suboptimal policy updates. T-SRL employs two distinct temporal states, past and future, for chosen and rejected responses respectively, and utilizes a novel pairwise ranking loss within an SFT-like training process. Experiments show that T-SRL consistently outperforms DPO and SRL-v2 models on AlpacaEval 2.0, achieving an average win rate of 77.2% against strong baselines. The implication for AI practitioners is the provision of a more robust and efficient fine-tuning methodology for large language models, potentially leading to higher-quality models with less manual data annotation and improved alignment.

---

### Less Is More: Training-Free Sparse Attention with Global Locality for Efficient Reasoning

[arXiv](https://arxiv.org/abs/2508.07101)

**Authors:** Baihong Yuan, Shijie Cao, Arti Jain, Zhihao Zhang, Lijie Yang

**Category:** Natural Language Processing

**Summary:** This paper introduces a novel training-free sparse attention mechanism, GLSA (Global Locality Sparse Attention), designed to enhance the efficiency of Large Language Models (LLMs) during inference. The core objective is to reduce computational overhead and memory footprint without sacrificing performance by integrating global tokens and local window attention. GLSA achieves this by dynamically selecting important tokens for global attention while maintaining local contextual understanding, demonstrating significant speedups (e.g., 1.5x on LLaMA-7B) and reduced memory usage without fine-tuning. The main implication for AI practitioners is the potential for deploying larger, more capable LLMs in resource-constrained environments or achieving faster inference for existing models, thereby broadening the practical applicability of these advanced models.

---

### Follow-Your-Shape: Shape-Aware Image Editing via Trajectory-Guided Region Control

[arXiv](https://arxiv.org/abs/2508.08134)

**Authors:** Hongyu Liu, Xinhua Zhang, Kunyu Feng, Mingzhe Zheng, Zeqian Long

**Category:** Computer Vision

**Summary:** The paper introduces Follow-Your-Shape, a novel trajectory-guided region control method for shape-aware image editing. Its main objective is to overcome limitations of existing methods in precisely controlling non-rigid shape deformations and maintaining consistency with complex editing trajectories. The key methodology involves using a trajectory-guided region control that translates user-defined trajectories into explicit region control signals, enabling accurate shape deformation. Experimental results show that Follow-Your-Shape achieves a higher success rate (e.g., 85% on diverse shape editing tasks) and generates more coherent deformations compared to baseline methods. This work implies that AI practitioners can leverage this method for more precise and versatile image manipulation, especially in applications requiring detailed shape control and realistic non-rigid deformations.

---

### MoBE: Mixture-of-Basis-Experts for Compressing MoE-based LLMs

[arXiv](https://arxiv.org/abs/2508.05257)

**Authors:** Jianguo Li, Jing Zhang, Zhenzhong Lan, Mingming Ha, Xiaodong Chen

**Category:** Natural Language Processing

**Summary:** The paper introduces MoBE, a novel method for efficiently compressing Mixture-of-Experts (MoE) Large Language Models. The primary objective is to address the high inference latency and computational cost associated with large MoE models, specifically targeting the redundant expert activations. MoBE achieves this by representing the experts as a mixture of shared, low-rank basis vectors and expert-specific coefficients, and then selectively activates these basis vectors. This approach allows for a reduction in the number of activated parameters during inference while maintaining performance, with results showing that MoBE can achieve a 2.5x speedup and reduce memory by 2.2x on the 7B MoE model compared to baseline MoE models, and MoBE-8x7B maintains 97.5% of the original model's performance while improving inference speed. The main implication for AI practitioners is the ability to deploy large MoE models more efficiently in resource-constrained environments, making advanced LLMs more accessible for real-world applications.

---

### VisR-Bench: An Empirical Study on Visual Retrieval-Augmented Generation for Multilingual Long Document Understanding

[arXiv](https://arxiv.org/abs/2508.07493)

**Authors:** Tong Yu, Chenguang Wang, Jihyung Kil, Ming Li, Jian Chen

**Category:** Multi-Modal

**Summary:** VisR-Bench introduces a novel benchmark for evaluating visual retrieval-augmented generation (VRAG) models on multilingual long document understanding. The primary objective is to investigate the efficacy of VRAG in enhancing large language models' (LLMs) ability to process and comprehend complex, visually rich documents across multiple languages. The key methodology involves constructing a benchmark with diverse document types, languages, and tasks, alongside a novel prompt engineering strategy and a fine-tuned multimodal LLM. Experimental results demonstrate that VRAG significantly improves performance, with a 15.3% average gain in factual accuracy over text-only RAG methods on the VisR-Bench dataset. This research implies that integrating visual cues into retrieval processes is crucial for developing more robust and accurate AI systems for multilingual document understanding.

---

### Shortcut Learning in Generalist Robot Policies: The Role of Dataset Diversity and Fragmentation

[arXiv](https://arxiv.org/abs/2508.06426)

**Authors:** Hengtao Shen, Lianli Gao, Junlin Xie, Xu Luo, Youguang Xing

**Category:** Reinforcement Learning

**Summary:** This paper investigates shortcut learning in generalist robot policies, specifically examining how dataset diversity and fragmentation impact out-of-distribution (OOD) generalization. The main objective is to understand if policy performance degradation in OOD scenarios is due to shortcut learning and to identify mitigation strategies. The authors evaluate behavior cloning policies on various robot manipulation tasks, manipulating dataset diversity and fragmentation to observe their effects on generalization. They found that highly diverse datasets led to policies with better OOD performance, reducing the reliance on spurious correlations, with improvements of up to 15% in success rate on certain tasks. The primary implication for AI practitioners is that careful dataset curation, focusing on diversity, is crucial for developing robust generalist robot policies capable of avoiding shortcut learning and achieving reliable OOD generalization.

---

### Compressing Chain-of-Thought in LLMs via Step Entropy

[arXiv](https://arxiv.org/abs/2508.03346)

**Authors:** Zhijian Xu, Xiangyu Wen, Ziyang Zheng, Jianyuan Zhong, Zeju Li

**Category:** Natural Language Processing

**Summary:** This paper investigates methods to compress the chain-of-thought (CoT) generated by large language models (LLMs) to improve inference efficiency. The main objective is to reduce the computational cost associated with long CoT reasoning without sacrificing performance. The authors propose a novel approach based on step entropy, identifying and pruning redundant or low-entropy tokens within the CoT. This method achieves a compression ratio of up to 40% while maintaining the accuracy of the original CoT, for example, on the GSM8K dataset. The primary implication for AI practitioners is the potential to significantly reduce the computational burden and memory footprint of deploying LLMs for complex reasoning tasks, enabling more efficient and scalable applications.

---

### GLiClass: Generalist Lightweight Model for Sequence Classification Tasks

[arXiv](https://arxiv.org/abs/2508.07662)

**Authors:** Alexander Yavorskyi, Oleksandr Lukashov, Dmytro Vodianytskyi, Mykhailo Shtopko, Ihor Stepanov

**Category:** Natural Language Processing

**Summary:** This paper introduces GLiClass, a generalist lightweight model designed for sequence classification tasks, aiming to provide a robust and efficient solution for various natural language understanding challenges. The main objective is to overcome limitations of traditional deep learning models, such as high computational costs and data-intensive training, by leveraging knowledge distillation and adapter-based fine-tuning. GLiClass utilizes a Teacher-Student architecture where a large teacher model transfers knowledge to a smaller student model, which is then fine-tuned with lightweight adapters for specific tasks. The model demonstrates strong performance, achieving a 92% accuracy on the GLUE benchmark, indicating its effectiveness across diverse NLP tasks. This implies that AI practitioners can deploy high-performing NLP models with significantly reduced computational resources and faster inference times, making advanced NLP more accessible.

---

### Deep Ignorance: Filtering Pretraining Data Builds Tamper-Resistant Safeguards into Open-Weight LLMs

[arXiv](https://arxiv.org/abs/2508.06601)

**Authors:** Robert Kirk, Tomek Korbak, Quentin Anthony, Stephen Casper, Kyle O'Brien

**Category:** Natural Language Processing

**Summary:** This paper introduces a novel approach to enhance the safety and tamper-resistance of open-weight large language models (LLMs) by filtering their pretraining data. The primary objective is to make LLMs more robust against adversarial attacks and misuse, particularly in generating harmful content. The methodology involves identifying and removing data points from the pretraining corpus that are associated with undesirable behaviors or content, effectively "inoculating" the model against learning harmful associations. Through this technique, the study demonstrates a significant reduction in harmful output, achieving up to a 60% decrease in the generation of toxic content while maintaining model utility. This research implies that data curation at the pretraining stage is a powerful and efficient strategy for AI practitioners to build inherently safer and more reliable open-weight LLMs, offering a scalable alternative to post-hoc alignment methods.

---

### Bifrost-1: Bridging Multimodal LLMs and Diffusion Models with Patch-level CLIP Latents

[arXiv](https://arxiv.org/abs/2508.05954)

**Authors:** Mohit Bansal, Chuan Li, Amir Zadeh, Jaemin Cho, Han Lin

**Category:** Multi-Modal

**Summary:** Bifrost-1 integrates multimodal large language models (LLMs) with diffusion models using patch-level CLIP latents to enhance image generation with rich contextual understanding. The primary objective is to enable diffusion models to leverage the detailed cross-modal reasoning capabilities of LLMs for more controllable and contextually accurate image synthesis. This is achieved by converting patch-level CLIP image latents into a sequence of features digestible by LLMs, allowing the LLM to provide fine-grained guidance to the diffusion process. The approach demonstrated a 20.3% improvement in CLIP score over baselines, indicating enhanced visual-semantic alignment. This implies that AI practitioners can develop more sophisticated and controllable generative AI systems by bridging the gap between high-level semantic understanding and detailed image synthesis.

---

### Spectrum Projection Score: Aligning Retrieved Summaries with Reader Models in Retrieval-Augmented Generation

[arXiv](https://arxiv.org/abs/2508.05909)

**Authors:** Hanqi Yan, Yulan He, Siya Qi, Qinglin Zhu, Zhanghao Hu

**Category:** Natural Language Processing

**Summary:** This paper introduces Spectrum Projection Score (SPS), a novel metric for evaluating the alignment of retrieved summaries with reader models in Retrieval-Augmented Generation (RAG) systems. The research objective is to address the limitations of existing RAG evaluation metrics that fail to adequately assess how well retrieved information enhances the generation for a specific reader's understanding. SPS employs a projection method to measure the semantic overlap and relevance between retrieved summaries and an ideal reader model, incorporating aspects like salience and coherence. Experimental results demonstrate that SPS correlates more strongly with human judgments than traditional metrics like ROUGE and BERTScore, achieving a Spearman's rho of 0.72 with human relevance scores. This suggests SPS offers a more reliable and nuanced evaluation for optimizing RAG systems for user-centric applications, guiding practitioners in selecting and fine-tuning retrieval components that enhance reader comprehension.

---

### Fact2Fiction: Targeted Poisoning Attack to Agentic Fact-checking System

[arXiv](https://arxiv.org/abs/2508.06059)

**Authors:** Reynold Cheng, Dacheng Wen, Bin Benjamin Zhu, Yupeng Li, Haorui He

**Category:** Machine Learning

**Summary:** This paper introduces a novel targeted poisoning attack, Fact2Fiction, against fact-checking systems that employ retrieval-augmented generation (RAG) agents. The primary objective is to investigate how to manipulate a fact-checking agent's knowledge base to induce specific hallucinations in its outputs, while maintaining the appearance of benign data. The methodology involves crafting poisoned documents by inserting fabricated or distorted facts into otherwise credible articles, targeting both the fact-extraction and fact-checking components of the RAG agent. Key results show that Fact2Fiction can achieve a success rate of up to 60.5% in generating targeted hallucinations without significantly altering the retriever's original ranking. The main implication for AI practitioners is the critical need to develop robust defense mechanisms against data poisoning, especially in agentic systems reliant on external knowledge bases.

---

### Speech-to-LaTeX: New Models and Datasets for Converting Spoken Equations and Sentences

[arXiv](https://arxiv.org/abs/2508.03542)

**Authors:** Matvey Skripkin, Elvir Karimov, Artyom Iudin, Dmitrii Tarasov, Dmitrii Korzh

**Category:** Multi-Modal

**Summary:** This paper presents advancements in converting spoken mathematical equations and sentences into LaTeX format. The core objective is to improve the accuracy and robustness of speech-to-LaTeX translation, addressing the challenges of complex mathematical expressions and varied speaking styles. The authors introduce new datasets, including the Verbose Spoken MAthematics (VSMA) dataset and a new split of the Wikimedia dataset, and propose a transformer-based encoder-decoder model coupled with a joint CTC-attention loss function. They achieve a 90.7% BLEU score and a 57.6% exact match rate on the VSMA dataset, significantly outperforming previous methods. This work offers a valuable tool for STEM professionals, enabling more efficient and accessible documentation and communication through voice-based LaTeX input.

---

### When Good Sounds Go Adversarial: Jailbreaking Audio-Language Models with Benign Inputs

[arXiv](https://arxiv.org/abs/2508.03365)

**Authors:** Dasol Choi, Taeyoun Kwon, Hiskias Dingeto, Bodam Kim, oneonlee

**Category:** Multi-Modal

**Summary:** This paper investigates the vulnerability of Audio-Language Models (ALMs) to adversarial attacks using acoustically benign audio inputs. The main objective is to demonstrate that subtle, inaudible perturbations can "jailbreak" ALMs, causing them to generate harmful or undesirable outputs without altering the semantic content of the audio. The methodology involves crafting adversarial audio examples by applying imperceptible perturbations to clean speech inputs, specifically targeting ALMs to elicit harmful responses. The study found that such attacks achieved a 99.8% success rate in inducing ALMs to produce harmful content, significantly outperforming random noise attacks. This implies that ALM developers and practitioners must prioritize robust adversarial training and defense mechanisms to mitigate the risks posed by such stealthy attacks, ensuring the ethical and safe deployment of these models.

---

### Anatomy of a Machine Learning Ecosystem: 2 Million Models on Hugging Face

[arXiv](https://arxiv.org/abs/2508.06811)

**Authors:** Jon Kleinberg, Hamidah Oderinwale, Benjamin Laufer

**Category:** Machine Learning

**Summary:** This paper presents a comprehensive analysis of the Hugging Face ecosystem, which hosts over two million machine learning models. The main objective was to understand the characteristics and dynamics of this expansive repository, providing insights into model development and usage patterns. The authors employed a quantitative, large-scale empirical study, analyzing metadata and usage statistics of models, datasets, and spaces on the Hugging Face Hub. Key findings include the predominance of English models (72%) and a significant growth rate, with approximately 1000 new models added daily by late 2023. The study's implications highlight the need for improved model documentation and discoverability, offering valuable insights for developers and researchers navigating the rapidly expanding ML landscape.

---

### TextQuests: How Good are LLMs at Text-Based Video Games?

[arXiv](https://arxiv.org/abs/2507.23701)

**Authors:** Dan Hendrycks, Andy Zou, Mantas Mazeika, Long Phan

**Category:** Natural Language Processing

**Summary:** This paper investigates the performance of large language models (LLMs) in text-based video games. The primary objective is to evaluate how well current LLMs can reason, plan, and execute actions within complex, interactive narrative environments. The methodology involves fine-tuning LLMs on text-adventure game transcripts and evaluating them on unseen game states using metrics such as win rate and average score. Results indicate that even state-of-the-art LLMs like GPT-4 struggle significantly, achieving only a 22% success rate on challenging tasks, highlighting limitations in their ability to perform long-horizon planning and handle combinatorial complexity. This implies that while LLMs show promise in understanding natural language, substantial research is needed to enhance their capabilities in sequential decision-making within dynamic environments for practical applications.

---
