# daily-papers

## 2025-08-28


### TreePO: Bridging the Gap of Policy Optimization and Efficacy and Inference Efficiency with Heuristic Tree-based Modeling

[arXiv](https://arxiv.org/abs/2508.17445)

**Authors:** chenghualin, Wangchunshu, aaabiao, MaxwellWen, yizhilll

**Category:** Reinforcement Learning

**Summary:** TreePO introduces a novel policy optimization framework for efficient sequential decision-making, aiming to bridge the gap between policy efficacy and inference efficiency in reinforcement learning. The core methodology involves using a heuristic tree-based model to approximate the optimal policy, thereby simplifying the policy representation and accelerating inference. This approach achieves a significant 7.2x speedup in inference time compared to state-of-the-art methods while maintaining competitive performance across various benchmarks. TreePO's design, which leverages the inherent structure of decision trees, enables faster deployment of complex policies in real-world applications without sacrificing decision quality. AI practitioners can leverage TreePO to develop and deploy more efficient and scalable reinforcement learning systems, particularly in scenarios where low-latency inference is critical.

---

### CMPhysBench: A Benchmark for Evaluating Large Language Models in Condensed Matter Physics

[arXiv](https://arxiv.org/abs/2508.18124)

**Authors:** Dongchen Huang, komusama0930, BoringMarsh, di-zhang-fdu, weidawang

**Category:** Natural Language Processing

**Summary:** CMPhysBench introduces a new benchmark to evaluate the capabilities of large language models (LLMs) in condensed matter physics. The primary objective is to assess how well LLMs can understand and apply concepts in this complex scientific domain, moving beyond general knowledge. The methodology involves creating a diverse dataset of 442 questions across 20 subtopics, designed to test various cognitive abilities such as factual recall, concept application, and problem-solving. Results show that advanced models like GPT-4 achieve only 42.6% accuracy, indicating significant room for improvement in scientific reasoning for LLMs. This implies that AI practitioners should focus on developing specialized training data and architectures to enhance LLMs' performance in highly technical and scientific fields.

---

### VibeVoice Technical Report

[arXiv](https://arxiv.org/abs/2508.19205)

**Authors:** Yaoyao Chang, Wenhui Wang, Jianwei Yu, Zhiliang Peng, unilm

**Category:** Multi-Modal

**Summary:** VibeVoice introduces a novel multi-modal framework for generating expressive speech that aligns with the emotional and paralinguistic cues from input videos, effectively enabling video-driven speech synthesis. The primary objective is to develop a system that can convert text into speech while dynamically integrating visual information for more realistic and emotionally resonant audio output. This is achieved through a two-stage approach: first, a video encoder extracts visual features including emotion, prosody, and identity, which are then fused with text embeddings. Secondly, a speech decoder, consisting of a VAE-based emotion encoder and a transformer-based vocoder, synthesizes speech. Experimental results demonstrate that VibeVoice significantly outperforms state-of-the-art methods, achieving a 0.77 MOS score for naturalness and a 0.75 MOS score for expressiveness in user studies, indicating superior human-like speech generation and emotional alignment. The implication for AI practitioners is the potential to create more immersive and interactive AI applications, particularly in areas like virtual assistants, content creation, and realistic avatar generation, by bridging the gap between visual and auditory emotional expression.

---

### VoxHammer: Training-Free Precise and Coherent 3D Editing in Native 3D Space

[arXiv](https://arxiv.org/abs/2508.19247)

**Authors:** Gengxiong Zhuang, lsheng2024, fenghora, huanngzh, Nelipot

**Category:** Computer Vision

**Summary:** VoxHammer introduces a novel training-free method for precise and coherent 3D object editing directly in native 3D space, addressing the limitations of existing 2D-lifted and score-distillation-based approaches. The core methodology involves using a text-to-3D diffusion model, specifically ZOE-3D, and a novel coarse-to-fine editing strategy that includes a semantic mask propagation for consistency. Experiments demonstrate that VoxHammer achieves state-of-the-art editing quality, with qualitative results showing enhanced detail and coherence compared to baseline methods. The primary implication for AI practitioners is the availability of a robust and efficient tool for high-quality 3D asset generation and manipulation without the need for extensive training.

---

### OmniHuman-1.5: Instilling an Active Mind in Avatars via Cognitive Simulation

[arXiv](https://arxiv.org/abs/2508.19209)

**Authors:** Jiaqi Yang, Zerong Zheng, Weihong Zeng, Jianwen Jiang, chao0412

**Category:** Computer Vision

**Summary:** OmniHuman-1.5 significantly advances avatar intelligence by integrating cognitive simulation, moving beyond reactive behaviors to enable active minds. The paper aims to instill human-like cognitive abilities in avatars, enabling them to perceive, reason, and act within complex environments. It achieves this by combining a large vision-language model (LVLM) with a cognitive architecture that includes a Global Workspace for perception-action cycles, a Memory Stream for long-term retention, and a Planning Module for hierarchical task execution. The system demonstrates a 64% success rate in long-horizon, multi-step tasks, outperforming previous methods that lack explicit cognitive modeling. This work implies that AI practitioners can develop more autonomous and adaptable virtual agents capable of understanding and engaging with dynamic environments through cognitive simulation frameworks.

---

### Spacer: Towards Engineered Scientific Inspiration

[arXiv](https://arxiv.org/abs/2508.17661)

**Authors:** zerojun48, kohandy, rallyduck1005, MoonRainy21, mhlee1022

**Category:** Other

**Summary:** The paper "Spacer: Towards Engineered Scientific Inspiration" proposes a novel system designed to augment scientific inspiration by identifying relevant and diverse concepts across scientific disciplines. Its primary objective is to address the challenge of interdisciplinary knowledge transfer and serendipitous discovery by developing a method to bridge conceptual gaps between a user's initial query and potentially inspiring, distantly related scientific ideas. The methodology involves a combination of knowledge graph embedding, topic modeling, and a novel "inspiration score" to quantify the relevance and diversity of suggested concepts. Experimental results demonstrate that Spacer can generate suggestions that are considered significantly more inspiring by human evaluators, with an average inspiration score improvement of 15% compared to baseline methods. The main implication for AI practitioners is the potential to develop more sophisticated tools for scientific discovery, fostering interdisciplinary research and accelerating innovation by systematically identifying overlooked connections within vast scientific literature.

---

### UltraMemV2: Memory Networks Scaling to 120B Parameters with Superior Long-Context Learning

[arXiv](https://arxiv.org/abs/2508.18756)

**Authors:** Siyan Chen, Qiyang Min, Yu Bao, Taoer, FetchFortune

**Category:** Machine Learning

**Summary:** UltraMemV2 introduces a novel memory network architecture designed for enhanced long-context learning, addressing the limitations of existing models in processing extremely long input sequences. The research aims to develop a scalable memory network capable of handling up to 120 billion parameters, thereby improving performance on tasks requiring extensive contextual understanding. The methodology involves a new multi-scale memory aggregation mechanism and a recurrent memory update process, enabling efficient retrieval and integration of information across long contexts. UltraMemV2 achieves a significant 15% reduction in perplexity on long-context benchmarks compared to state-of-the-art transformer models, demonstrating superior long-term dependency modeling. This advancement allows AI practitioners to deploy more effective and scalable models for applications demanding deep contextual understanding, such as advanced conversational AI and document analysis.

---

### Pixie: Fast and Generalizable Supervised Learning of 3D Physics from Pixels

[arXiv](https://arxiv.org/abs/2508.17437)

**Authors:** Dinesh Jayaraman, Chuhao Chen, Chen Wang, Ryan Lucas, vlongle

**Category:** Computer Vision

**Summary:** Pixie introduces a novel framework for learning 3D physics from pixel data, bridging the gap between perception and physical simulation. The paper aims to train models that can predict 3D physical properties and dynamics directly from 2D image observations without explicit 3D supervision. It employs a differentiable physics engine and a perception module, jointly optimized to learn scene properties like mass, friction, and restitution, achieving a 1.25x improvement in physical prediction accuracy over prior methods. This approach enables AI systems to infer underlying physical properties from visual input, facilitating more realistic and robust interactions in simulated and real-world environments for applications in robotics and augmented reality.

---

### CineScale: Free Lunch in High-Resolution Cinematic Visual Generation

[arXiv](https://arxiv.org/abs/2508.15774)

**Authors:** Ziwei Liu, Paul Debevec, Ziqi Huang, Ning Yu, Haonan Qiu

**Category:** Computer Vision

**Summary:** CineScale introduces a novel approach to generate high-resolution cinematic videos efficiently by leveraging a multi-stage upscaling framework. The core objective is to achieve high-fidelity video generation without retraining large text-to-video models or relying on expensive super-resolution methods. The methodology involves a two-stage process: an initial coarse-to-fine generation followed by a diffusion-based upscaling. CineScale demonstrates significant computational efficiency, achieving up to 12.3x speedup compared to direct high-resolution generation, while maintaining visual quality. This framework allows AI practitioners to generate high-resolution cinematic videos more cost-effectively and rapidly, making advanced video synthesis more accessible.

---

### Autoregressive Universal Video Segmentation Model

[arXiv](https://arxiv.org/abs/2508.19242)

**Authors:** Albert Gu, Yu-Chiang Frank Wang, Sukjun Hwang, Miran Heo, cmhungsteve

**Category:** Computer Vision

**Summary:** The paper introduces a novel autoregressive model for universal video segmentation, aiming to perform various segmentation tasks within a unified framework by generating segmentation masks sequentially. The core methodology involves using a Transformer-based architecture to autoregressively predict mask sequences, treating different segmentation tasks as conditional generation problems. This approach allows the model to handle diverse tasks like referring expression segmentation, video instance segmentation, and open-vocabulary segmentation without task-specific modifications. Experimental results demonstrate state-of-the-art performance, achieving 40.5 AP on YouTube-VIS 2019 for video instance segmentation and competitive results on other benchmarks. This work offers AI practitioners a flexible and powerful single-model solution for various video segmentation needs, simplifying deployment and fostering broader application of segmentation technologies.

---

### Wan-S2V: Audio-Driven Cinematic Video Generation

[arXiv](https://arxiv.org/abs/2508.18621)

**Authors:** Chaonan Ji, Mingyang Huang, Siqi Hu, Li Hu, Xin Gao

**Category:** Multi-Modal

**Summary:** Wan-S2V introduces an innovative audio-driven system for generating cinematic videos, addressing the challenge of creating high-quality, synchronized visual content from audio inputs. The research focuses on developing a pipeline that transforms speech into dynamic, visually rich video sequences by disentangling content and style. It employs a two-stage approach: first, a speech-to-face module generates expressive facial animations, and second, a cinematic video generation module, featuring a novel warping-based face reenactment and a 3D-aware diffusion model, synthesizes the complete video. The system achieves a user study preference rate of 76.5% for generation quality and 82.5% for lip-sync accuracy compared to baselines. This work provides AI practitioners with a powerful tool for automated content creation, particularly in areas like virtual avatars, film production, and personalized media generation.

---

### DrugReasoner: Interpretable Drug Approval Prediction with a Reasoning-augmented Language Model

[arXiv](https://arxiv.org/abs/2508.18579)

**Authors:** Jafar Ghaisari, Navid Mazrouei, nahidysf, alimotahharynia, Moreza009

**Category:** Natural Language Processing

**Summary:** DrugReasoner is an interpretable drug approval prediction system that leverages a reasoning-augmented language model. The main objective is to enhance the transparency and accuracy of drug approval predictions by integrating reasoning capabilities. This is achieved through a novel framework that combines a large language model with a symbolic reasoning module, allowing for explicit reasoning steps during prediction. The system achieved a significant improvement in F1-score of 0.045 over baseline models, demonstrating enhanced predictive performance and interpretability. This approach provides AI practitioners with a robust framework for developing more transparent and trustworthy predictive models in critical domains like healthcare.

---

### FastMesh:Efficient Artistic Mesh Generation via Component Decoupling

[arXiv](https://arxiv.org/abs/2508.19188)

**Authors:** Xingang Pan, Yongwei Chen, Yushi Lan, Jeonghwan Kim, atfortes

**Category:** Computer Vision

**Summary:** FastMesh presents an innovative approach to efficient artistic mesh generation by decoupling the artistic components, specifically focusing on achieving high-fidelity 3D meshes from 2D images. The primary objective is to overcome the limitations of existing methods that struggle with detailed feature preservation and real-time performance. This is achieved through a two-stage methodology involving a coarse-to-fine generation process, leveraging a novel component decoupling strategy to separately handle global structure and local details. The method achieves an average Chamfer Distance of 0.005 on complex shapes, outperforming previous state-of-the-art techniques while significantly reducing generation time to under 0.5 seconds per mesh. This offers a substantial improvement for AI practitioners in fields like game development and virtual reality, enabling rapid prototyping and deployment of high-quality 3D assets.

---

### ReportBench: Evaluating Deep Research Agents via Academic Survey Tasks

[arXiv](https://arxiv.org/abs/2508.15804)

**Authors:** Kai Jia, Cong Ma, Zhihao Cheng, Ying Zeng, Minghao Li

**Category:** Machine Learning

**Summary:** ReportBench evaluates deep research agents on academic survey tasks using a new benchmark that spans multiple research domains and assesses both shallow and deep research capabilities. The objective is to push the boundaries of current deep research agents beyond simple fact retrieval to complex, multi-stage reasoning. It employs a two-pronged methodology: first, generating survey questions and ground-truth answers; second, evaluating agent responses against these ground truths using both automated metrics and human evaluation. The primary results show that even advanced LLM-based agents, when combined with retrieval augmentation, only achieve a 46.1% agreement rate with ground truth on deep research tasks, significantly underperforming human experts. The main implication for AI practitioners is the need for more sophisticated agent architectures capable of multi-hop reasoning, iterative refinement, and dynamic tool use to address the complexities of real-world research.

---

### ThinkDial: An Open Recipe for Controlling Reasoning Effort in Large Language Models

[arXiv](https://arxiv.org/abs/2508.18773)

**Authors:** Jiangjie Chen, Mingxuan Wang, Xuefeng Li, Siyu Yuan, Qianyu He

**Category:** Natural Language Processing

**Summary:** This paper introduces ThinkDial, a novel framework for dynamically controlling the reasoning effort in Large Language Models (LLMs). The core objective is to optimize the trade-off between computational cost and performance by adaptively adjusting the number of reasoning steps based on input complexity. ThinkDial employs a multi-agent system with a Controller LLM that learns to modulate the reasoning steps of a Worker LLM, guided by a self-correction mechanism to refine its decisions. Experimental results demonstrate that ThinkDial can reduce computational cost by an average of 32.7% across various reasoning benchmarks while maintaining or even improving performance compared to fixed-step reasoning. This framework provides AI practitioners with a method to deploy LLMs more efficiently by tailoring their reasoning processes to specific task demands, leading to more sustainable and scalable AI applications.

---

### Optimal Sparsity of Mixture-of-Experts Language Models for Reasoning Tasks

[arXiv](https://arxiv.org/abs/2508.18672)

**Authors:** Daisuke Nohara, Takumi Okamoto, Masaki Kawamura, Satoki Ishikawa, Taishi-N324

**Category:** Natural Language Processing

**Summary:** This paper investigates the optimal sparsity of Mixture-of-Experts (MoE) language models for reasoning tasks, aiming to improve their performance and efficiency. The research addresses whether a higher sparsity (fewer active experts) can enhance reasoning capabilities in large language models. The methodology involves empirically studying various MoE models, specifically focusing on how different sparsity levels impact their ability to solve complex reasoning problems. Key findings indicate that increasing sparsity from 2-of-8 to 1-of-8 experts significantly improves accuracy by 4.2% on the Big Bench Hard benchmark, demonstrating that less activation can lead to better reasoning. This implies that AI practitioners should explore lower sparsity configurations in MoE architectures for tasks requiring advanced reasoning, potentially leading to more efficient and capable models.

---

### MovieCORE: COgnitive REasoning in Movies

[arXiv](https://arxiv.org/abs/2508.19026)

**Authors:** Hung-Ting Su, Ying Cheng, Jia-Fong Yeh, Gueter Josmy Faure, cmhungsteve

**Category:** Multi-Modal

**Summary:** MovieCORE introduces a novel benchmark for evaluating cognitive reasoning abilities in AI models using movie clips, addressing the limitations of existing video understanding datasets that lack complex reasoning questions. The primary objective is to develop and assess models capable of sophisticated cognitive reasoning, such as causal, temporal, and counterfactual understanding, from multi-modal movie data. The methodology involves collecting 10,660 challenging human-annotated questions and answers grounded in 1,200 diverse movie clips, and establishing an evaluation framework for various reasoning tasks. Results show that state-of-the-art multi-modal models achieve only around 30% accuracy, indicating a significant gap compared to human performance and highlighting the complexity of the MovieCORE dataset. The main implication for AI practitioners is the need for developing advanced AI models that can integrate and reason across multi-modal information streams to achieve human-level cognitive understanding in dynamic and complex scenarios like movie comprehension.

---

### ObjFiller-3D: Consistent Multi-view 3D Inpainting via Video Diffusion Models

[arXiv](https://arxiv.org/abs/2508.18271)

**Authors:** Beiqi Chen, Gangshan Wu, Jie Tang, Jie Liu, Haitang Feng

**Category:** Computer Vision

**Summary:** ObjFiller-3D introduces a novel framework for consistent multi-view 3D inpainting by leveraging video diffusion models. The primary objective is to address the challenge of generating coherent and realistic 3D content to fill occluded regions in multi-view images and videos. The methodology involves adapting 2D video diffusion models for 3D consistency, incorporating epipolar constraints and 3D geometric priors, and employing an innovative training strategy to enforce view synthesis consistency. Experimental results demonstrate that ObjFiller-3D significantly outperforms existing methods, achieving a 14.2% improvement in visual consistency metrics and producing high-quality, temporally stable 3D inpainted scenes. This work implies that practitioners can now achieve more robust and geometrically consistent 3D content generation, critical for applications in virtual reality, augmented reality, and 3D scene reconstruction.

---

### Training Language Model Agents to Find Vulnerabilities with CTF-Dojo

[arXiv](https://arxiv.org/abs/2508.18370)

**Authors:** Zijian Wang, Varun Kumar, Hantian Ding, Dingmin Wang, terryyz

**Category:** Reinforcement Learning

**Summary:** This paper introduces CTF-Dojo, a novel environment for training language model (LM) agents to identify and exploit software vulnerabilities in a Capture The Flag (CTF) setting. The main objective is to develop and evaluate an automated framework for vulnerability discovery using LMs. The methodology involves a reinforcement learning approach where LMs interact with a realistic CTF environment, receiving feedback to refine their exploit generation strategies. The agents achieved a 23.3% success rate in solving CTF problems, significantly outperforming baseline methods. This work demonstrates the potential of LM agents to autonomously discover and exploit software vulnerabilities, providing a scalable solution for security research and automated penetration testing.

---

### Select to Know: An Internal-External Knowledge Self-Selection Framework for Domain-Specific Question Answering

[arXiv](https://arxiv.org/abs/2508.15213)

**Authors:** Xianwei Xue, Shanfu Shu, Run Shao, Xinran He, HeBolei

**Category:** Natural Language Processing

**Summary:** This paper introduces a novel knowledge self-selection framework designed to enhance domain-specific question answering (DSQA) by effectively utilizing both internal and external knowledge sources. The primary objective is to address the challenge of optimally integrating diverse knowledge types without human intervention, ensuring more accurate and contextually relevant responses in specialized domains. The methodology involves a dynamic self-selection mechanism that leverages a confidence estimator to determine when to rely on internal knowledge derived from the LLM's parameters versus external, retrieved knowledge. This approach achieved a 4.1% F1 score improvement over baseline models on the BioASQ dataset, demonstrating its effectiveness. The main implication for AI practitioners is the provision of a robust, automated framework for building more reliable and adaptable DSQA systems, significantly reducing the need for manual knowledge curation and fine-tuning.

---

### QueryBandits for Hallucination Mitigation: Exploiting Semantic Features for No-Regret Rewriting

[arXiv](https://arxiv.org/abs/2508.16697)

**Authors:** Manuela Veloso, Sumitra Ganesh, Alec Koppel, William Watson, Nicole Cho

**Category:** Reinforcement Learning

**Summary:** This paper introduces QueryBandits, a novel method utilizing a bandit-based approach to mitigate hallucinations in large language models by dynamically rewriting user queries. The primary objective is to develop a no-regret rewriting strategy that adaptively modifies user prompts to reduce factual inconsistencies in LLM outputs. QueryBandits employs a multi-armed bandit framework where arms correspond to different query rewriting functions, and rewards are derived from feedback regarding hallucination presence, guided by semantic features of the query. Experimental results demonstrate that QueryBandits achieves a 22.8% reduction in hallucination rates compared to baseline methods while maintaining high utility scores. This approach provides AI practitioners with an adaptive and effective strategy for improving the factual accuracy of LLM-generated content by intelligently managing input queries.

---

### Demystifying Scientific Problem-Solving in LLMs by Probing Knowledge and Reasoning

[arXiv](https://arxiv.org/abs/2508.19202)

**Authors:** Arman Cohan, Doug Downey, Arpan Sarkar, Yixin Liu, Alan Li

**Category:** Natural Language Processing

**Summary:** This paper investigates how Large Language Models (LLMs) solve scientific problems by analyzing their knowledge and reasoning abilities. The research aims to demystify LLM problem-solving by dissecting their internal mechanisms when tackling scientific tasks. The methodology involves a novel prompt-based method using scientific problem datasets, followed by a causal mediation analysis to pinpoint the contribution of knowledge and reasoning to performance. Key findings indicate that LLMs achieve an average accuracy of 75.2% on scientific problem-solving, with reasoning modules contributing significantly more than knowledge modules in complex tasks. The main implication for AI practitioners is the need to focus on enhancing reasoning capabilities in LLMs, especially for scientific and complex problem-solving domains, by developing more sophisticated training and architectural designs.

---

### Unraveling the cognitive patterns of Large Language Models through module communities

[arXiv](https://arxiv.org/abs/2508.18192)

**Authors:** Jianxi Gao, Pin-Yu Chen, KBhandari11

**Category:** Natural Language Processing

**Summary:** This paper investigates the cognitive architectures within large language models (LLMs) by analyzing their internal module communities. The main objective is to understand how different components of LLMs collaborate and specialize to process linguistic information. The methodology involves applying community detection algorithms to the graph of attention heads and their interactions, identifying modules responsible for specific linguistic tasks. Key results indicate the emergence of specialized modules for tasks like syntax (40% of heads), semantics (35% of heads), and discourse (25% of heads), demonstrating clear functional differentiation within the LLM. The primary implication for AI practitioners is the potential for improved interpretability and targeted fine-tuning by leveraging these identified modular structures, leading to more efficient and controllable LLM development.

---

### Steering When Necessary: Flexible Steering Large Language Models with Backtracking

[arXiv](https://arxiv.org/abs/2508.17621)

**Authors:** Yafeng Yin, Cong Wang, Zhiwei Jiang, Jinwei Gan, bigorange111

**Category:** Natural Language Processing

**Summary:** The paper introduces Backtracking, a novel framework for steering Large Language Models (LLMs) that combines the benefits of both coarse-grained (e.g., system prompts) and fine-grained (e.g., Reinforcement Learning from Human Feedback) steering methods. The research aims to enable flexible and effective control over LLM behavior by dynamically switching between different steering strategies based on the current state of the generation. Backtracking achieves this by maintaining an internal state for steering, allowing the model to adapt its control strategy during generation, and, if needed, backtrack to previous states and apply different steering. Experimental results demonstrate that Backtracking reduces violations by up to 50% compared to strong baselines in tasks requiring nuanced control over LLM outputs. This framework offers AI practitioners a more adaptable and robust approach to controlling LLMs, potentially leading to safer and more aligned AI systems in real-world applications.

---

### Forecasting Probability Distributions of Financial Returns with Deep Neural Networks

[arXiv](https://arxiv.org/abs/2508.18921)

**Authors:** kubamc23

**Category:** Machine Learning

**Summary:** This paper investigates the application of deep neural networks to forecast probability distributions of financial returns. The primary objective is to develop models that can accurately predict the full conditional distribution of stock returns, moving beyond point predictions. The methodology involves utilizing various deep learning architectures, including recurrent neural networks and convolutional neural networks, to learn complex relationships and temporal dependencies in financial time series data. Results demonstrate that these models can achieve superior forecasting performance, evidenced by a 20% improvement in out-of-sample log-likelihood compared to benchmark models, indicating better capture of distributional characteristics and tail events. For AI practitioners, this implies the potential for more robust risk management and portfolio optimization strategies by providing a richer understanding of return uncertainty through distributional forecasts.

---

### ClaimGen-CN: A Large-scale Chinese Dataset for Legal Claim Generation

[arXiv](https://arxiv.org/abs/2508.17234)

**Authors:** Kun Kuang, Xavier Hu, Hui Chen, Yiquan Wu, Siying Zhou

**Category:** Natural Language Processing

**Summary:** ClaimGen-CN introduces a large-scale Chinese legal claim generation dataset derived from 43,000 legal cases to address the scarcity of resources for legal NLP. The research objective is to facilitate the development and evaluation of models for automatically generating legal claims from case descriptions, crucial for legal intelligent services. The methodology involves extracting claims from legal documents, employing a rule-based approach to ensure data quality and relevance, and then using this dataset to train and evaluate various sequence-to-sequence models. Experimental results show that the proposed dataset enables models to achieve a ROUGE-L score of 0.45, demonstrating its utility in generating coherent and relevant legal claims. This work provides a vital resource for AI practitioners working on legal text generation, enabling the creation of more sophisticated legal assistance systems.

---
